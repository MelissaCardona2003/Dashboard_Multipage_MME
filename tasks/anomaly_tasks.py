"""
Tareas Celery para detecciÃ³n de anomalÃ­as y envÃ­o de alertas automÃ¡ticas.

- check_anomalies: Cada 30 minutos evalÃºa el sistema energÃ©tico.
  SOLO envÃ­a notificaciÃ³n cuando detecta anomalÃ­as CRÃTICAS realmente urgentes.
  NO envÃ­a si la misma alerta ya fue notificada en las Ãºltimas 6 horas.
- send_daily_summary: Resumen diario a las 8:00 AM (siempre se envÃ­a).

Cuando detecta anomalÃ­as crÃ­ticas, envÃ­a por Telegram + email
usando NotificationService.
"""
import logging
import re as _re
import sys
import os
from datetime import datetime, date, timedelta
from celery import shared_task

# Asegurar que el directorio raÃ­z del proyecto estÃ© en el path
_PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
if _PROJECT_ROOT not in sys.path:
    sys.path.insert(0, _PROJECT_ROOT)

logger = logging.getLogger(__name__)

# ConfiguraciÃ³n del bot de Oscar
BOT_BROADCAST_URL = "http://localhost:8001/api/broadcast-alert"
BOT_TIMEOUT = 60

# â”€â”€ Cooldown: no reenviar la misma alerta dentro de este perÃ­odo â”€â”€
ALERT_COOLDOWN_HOURS = 6


def _clean_markdown_for_telegram(text: str) -> str:
    """Convierte markdown estÃ¡ndar (##, ###, **, -) a Telegram Markdown v1."""
    # Quitar tÃ­tulo general si quedÃ³ (# INFORME...)
    text = _re.sub(r'^#\s+INFORME.+\n?', '', text)
    text = _re.sub(r'^ğŸ“…\s*Fecha:.+\n?', '', text, flags=_re.MULTILINE)
    # ## N. TÃ­tulo â†’ *N. TÃ­tulo* (negrita Telegram)
    text = _re.sub(
        r'^##\s*(\d+\.\s*.+)$',
        r'*\1*',
        text,
        flags=_re.MULTILINE,
    )
    # ### N.N SubtÃ­tulo â†’ _N.N SubtÃ­tulo_ (itÃ¡lica Telegram)
    text = _re.sub(
        r'^###?\s*(\d+\.\d+\s*.+)$',
        r'_\1_',
        text,
        flags=_re.MULTILINE,
    )
    # **texto** â†’ *texto* (negrita Telegram)
    text = _re.sub(r'\*\*(.+?)\*\*', r'*\1*', text)
    # - item â†’ â–¸ item
    text = _re.sub(r'^-\s+', 'â–¸ ', text, flags=_re.MULTILINE)
    #   - sub-item â†’ Â· sub-item
    text = _re.sub(r'^\s{2,}-\s+', '  Â· ', text, flags=_re.MULTILINE)
    return text.strip()


def _broadcast_alert_via_bot(message: str, severity: str = "ALERT") -> dict:
    """
    EnvÃ­a alerta a TODOS los usuarios del bot via el endpoint broadcast.
    El bot de Oscar (puerto 8001) se encarga de enviar a cada usuario
    que alguna vez haya interactuado con el chatbot.
    """
    import requests
    try:
        payload = {
            "message": message,
            "severity": severity
        }
        response = requests.post(
            BOT_BROADCAST_URL,
            json=payload,
            timeout=BOT_TIMEOUT
        )
        if response.status_code == 200:
            result = response.json()
            logger.info(
                f"âœ… Broadcast completado: {result.get('sent', 0)} enviados "
                f"de {result.get('users_count', 0)} usuarios"
            )
            return result
        else:
            logger.warning(f"âš ï¸ Bot respondiÃ³ {response.status_code}: {response.text}")
            return {"status": "error", "code": response.status_code}
    except requests.exceptions.ConnectionError:
        logger.warning("âš ï¸ Bot de WhatsApp no disponible (puerto 8001). Alerta registrada pero no enviada.")
        return {"status": "bot_unavailable", "sent": 0}
    except Exception as e:
        logger.error(f"âŒ Error en broadcast via bot: {e}")
        return {"status": "error", "error": str(e)}


def _registrar_alerta_bd(alertas: list, enviados: int):
    """Registra las alertas enviadas en la tabla alertas_historial"""
    try:
        from infrastructure.database.connection import PostgreSQLConnectionManager
        import psycopg2
        import json

        manager = PostgreSQLConnectionManager()
        conn_params = {
            'host': manager.host,
            'port': manager.port,
            'database': manager.database,
            'user': manager.user
        }
        if manager.password:
            conn_params['password'] = manager.password
        conn = psycopg2.connect(**conn_params)
        cur = conn.cursor()

        for alerta in alertas[:5]:
            try:
                cur.execute("""
                    INSERT INTO alertas_historial 
                    (fecha_evaluacion, metrica, severidad, descripcion, 
                     valor_promedio, json_completo,
                     notificacion_whatsapp_enviada)
                    VALUES (%s, %s, %s, %s, %s, %s, %s)
                """, (
                    date.today(),
                    alerta.get('categoria', alerta.get('metrica', 'SISTEMA')),
                    alerta.get('severidad', 'ALERTA'),
                    alerta.get('titulo', alerta.get('descripcion', '')),
                    alerta.get('valor', 0),
                    json.dumps(alerta, ensure_ascii=False, default=str),
                    enviados > 0
                ))
            except Exception as e:
                logger.warning(f"No se pudo insertar alerta individual: {e}")
                conn.rollback()
                continue

        conn.commit()
        cur.close()
        conn.close()
        logger.info(f"ğŸ“ {len(alertas[:5])} alertas registradas en BD")
    except Exception as e:
        logger.error(f"Error registrando alertas en BD: {e}")


def _check_stale_data():
    """
    Detecta mÃ©tricas con datos congelados (mismos valores repetidos N dÃ­as).
    Retorna lista de alertas para mÃ©tricas potencialmente estancadas.
    """
    stale_alerts = []
    try:
        from infrastructure.database.connection import PostgreSQLConnectionManager
        import psycopg2

        manager = PostgreSQLConnectionManager()
        conn_params = {
            'host': manager.host, 'port': manager.port,
            'database': manager.database, 'user': manager.user
        }
        if manager.password:
            conn_params['password'] = manager.password
        conn = psycopg2.connect(**conn_params)
        cur = conn.cursor()

        # MÃ©tricas crÃ­ticas a monitorear por datos congelados
        metricas_criticas = [
            ('CapaUtilDiarEner', 3),   # Alertar si 3+ dÃ­as idÃ©nticos
            ('PorcVoluUtilDiar', 3),
            ('AporEner', 5),
            ('DemaReal', 2),
            ('Gene', 2),
        ]

        for metrica, max_dias_repetidos in metricas_criticas:
            cur.execute("""
                WITH daily_totals AS (
                    SELECT fecha, SUM(valor_gwh) as total
                    FROM metrics 
                    WHERE metrica = %s 
                    AND fecha >= CURRENT_DATE - INTERVAL '10 days'
                    GROUP BY fecha
                    ORDER BY fecha DESC
                    LIMIT 10
                )
                SELECT COUNT(*) as dias_iguales
                FROM daily_totals
                WHERE total = (SELECT total FROM daily_totals ORDER BY fecha DESC LIMIT 1)
            """, (metrica,))

            row = cur.fetchone()
            if row and row[0] > max_dias_repetidos:
                dias_frozen = row[0]
                stale_alerts.append({
                    'categoria': f'DATOS_CONGELADOS',
                    'metrica': metrica,
                    'severidad': 'ALERTA',
                    'titulo': f'{metrica}: datos idÃ©nticos {dias_frozen} dÃ­as consecutivos',
                    'descripcion': f'La mÃ©trica {metrica} muestra el mismo valor total '
                                   f'durante {dias_frozen} dÃ­as seguidos. Posible problema '
                                   f'con la API XM o el ETL.',
                    'valor': dias_frozen
                })
                logger.warning(
                    f"âš ï¸ {metrica}: datos congelados {dias_frozen} dÃ­as "
                    f"(umbral: {max_dias_repetidos})"
                )

        cur.close()
        conn.close()
    except Exception as e:
        logger.error(f"Error en detecciÃ³n de datos congelados: {e}")
    
    return stale_alerts


def _alerta_ya_notificada(titulo: str, horas: int = ALERT_COOLDOWN_HOURS) -> bool:
    """
    Verifica si una alerta con el mismo tÃ­tulo ya fue notificada
    dentro de las Ãºltimas `horas` horas, para evitar spam.
    """
    try:
        from infrastructure.database.connection import PostgreSQLConnectionManager
        import psycopg2

        manager = PostgreSQLConnectionManager()
        conn_params = {
            'host': manager.host, 'port': manager.port,
            'database': manager.database, 'user': manager.user
        }
        if manager.password:
            conn_params['password'] = manager.password
        conn = psycopg2.connect(**conn_params)
        cur = conn.cursor()
        cur.execute(
            """
            SELECT COUNT(*) FROM alertas_historial
            WHERE descripcion = %s
              AND (notificacion_whatsapp_enviada = TRUE
                   OR notificacion_email_enviada = TRUE)
              AND fecha_generacion >= NOW() - INTERVAL '%s hours'
            """,
            (titulo, horas),
        )
        count = cur.fetchone()[0]
        cur.close()
        conn.close()
        return count > 0
    except Exception as e:
        logger.warning(f"Error verificando cooldown de alerta: {e}")
        return False  # En caso de error, permitir enviar


@shared_task(name='tasks.anomaly_tasks.check_anomalies', bind=True, max_retries=2)
def check_anomalies(self):
    """
    Tarea periÃ³dica: detectar anomalÃ­as en el sistema energÃ©tico.

    POLÃTICA DE NOTIFICACIÃ“N:
      - Solo se envÃ­a notificaciÃ³n por Telegram/email cuando hay anomalÃ­as
        de severidad CRÃTICO (urgencias reales que el Viceministro debe conocer).
      - Las alertas de severidad ALERTA se registran en BD y logs pero NO
        se envÃ­an como notificaciÃ³n push.
      - Cooldown de 6 horas: si la misma alerta ya fue notificada recientemente,
        no se reenvÃ­a para evitar spam.
      - El informe diario (8:00 AM) sÃ­ incluye TODAS las anomalÃ­as detectadas.
    """
    try:
        logger.info("ğŸ” [ANOMALÃAS] Verificando anomalÃ­as en el sistema...")

        from scripts.alertas_energeticas import SistemaAlertasEnergeticas

        sistema = SistemaAlertasEnergeticas()
        try:
            # Evaluar todas las mÃ©tricas
            sistema.evaluar_demanda(horizonte=7)
            sistema.evaluar_aportes_hidricos(horizonte=7)
            sistema.evaluar_embalses(horizonte=7)
            sistema.evaluar_precio_bolsa(horizonte=7)
            sistema.evaluar_balance_energetico(horizonte=7)
        finally:
            sistema.close()

        alertas = sistema.alertas
        alertas_criticas = [a for a in alertas if a.get('severidad') in ('CRÃTICO', 'ALERTA')]

        # â”€â”€ DetecciÃ³n de datos congelados â”€â”€
        staleness_alerts = _check_stale_data()
        if staleness_alerts:
            alertas_criticas.extend(staleness_alerts)
            logger.warning(f"âš ï¸ [ANOMALÃAS] {len(staleness_alerts)} mÃ©tricas con datos congelados")

        # Registrar TODAS las alertas en BD (para el informe diario)
        if alertas_criticas:
            _registrar_alerta_bd(alertas_criticas, 0)
            logger.info(f"ğŸ“ [ANOMALÃAS] {len(alertas_criticas)} anomalÃ­as registradas en BD")

        # â”€â”€ FILTRO DE URGENCIA â”€â”€
        # Solo notificar las CRÃTICAS (no las de severidad ALERTA)
        alertas_urgentes = [
            a for a in alertas_criticas
            if a.get('severidad') == 'CRÃTICO'
        ]

        # â”€â”€ FILTRO DE COOLDOWN â”€â”€
        # Eliminar las que ya fueron notificadas en las Ãºltimas N horas
        alertas_nuevas = []
        for a in alertas_urgentes:
            titulo = a.get('titulo', a.get('descripcion', ''))
            if not _alerta_ya_notificada(titulo):
                alertas_nuevas.append(a)
            else:
                logger.info(
                    f"â³ [ANOMALÃAS] Alerta ya notificada recientemente, omitiendo: {titulo}"
                )

        if alertas_nuevas:
            logger.warning(
                f"ğŸš¨ [ANOMALÃAS] {len(alertas_nuevas)} anomalÃ­as CRÃTICAS NUEVAS â†’ notificando"
            )

            # Construir mensaje
            alert_lines = []
            max_severity = "CRITICAL"
            for a in alertas_nuevas[:5]:
                categoria = a.get('categoria', 'Sistema')
                titulo = a.get('titulo', 'AnomalÃ­a detectada')
                icon = 'ğŸ”´'
                alert_lines.append(f"{icon} *{categoria}*: {titulo}")

            alert_message = (
                f"ğŸš¨ *ALERTA URGENTE - SISTEMA ELÃ‰CTRICO* ğŸš¨\n\n"
                f"{chr(10).join(alert_lines)}\n\n"
                f"ğŸ“… Fecha: {datetime.now().strftime('%Y-%m-%d %H:%M')}\n"
                f"ğŸ“Š Total alertas crÃ­ticas: {len(alertas_nuevas)}\n\n"
                f"_Portal EnergÃ©tico - Ministerio de Minas y EnergÃ­a_"
            )

            # Enviar broadcast (Telegram + email)
            from domain.services.notification_service import broadcast_alert as ns_broadcast

            broadcast_result = ns_broadcast(
                message=alert_message,
                severity=max_severity,
                is_daily=False,
            )
            enviados = (
                broadcast_result.get('telegram', {}).get('sent', 0)
                + broadcast_result.get('email', {}).get('sent', 0)
            )

            # Actualizar BD con estado de envÃ­o
            _registrar_alerta_bd(alertas_nuevas, enviados)

            logger.info(f"ğŸ“¤ [ANOMALÃAS] Broadcast completado: {enviados} usuarios notificados")
        elif alertas_criticas:
            logger.info(
                f"ğŸ“‹ [ANOMALÃAS] {len(alertas_criticas)} anomalÃ­as detectadas "
                f"(ninguna crÃ­tica nueva para notificar)"
            )
        else:
            logger.info("âœ… [ANOMALÃAS] No se detectaron anomalÃ­as crÃ­ticas")

        return {
            "status": "completed",
            "timestamp": datetime.now().isoformat(),
            "anomalies_found": len(alertas_criticas) if alertas_criticas else 0,
            "critical_new": len(alertas_nuevas) if alertas_nuevas else 0,
            "notified": len(alertas_nuevas) > 0 if alertas_nuevas else False,
            "total_evaluated": len(alertas)
        }

    except Exception as e:
        logger.error(f"âŒ [ANOMALÃAS] Error verificando anomalÃ­as: {str(e)}", exc_info=True)
        raise self.retry(exc=e, countdown=120)


@shared_task(name='tasks.anomaly_tasks.send_daily_summary')
def send_daily_summary():
    """
    Tarea diaria (8:00 AM): genera el informe ejecutivo completo.

    Combina:
      - Texto narrativo generado por IA (informe_ejecutivo)
      - Datos estructurados reales (KPIs, predicciones, anomalÃ­as, noticias)
      - 3 grÃ¡ficos PNG (generaciÃ³n pie, embalses mapa, precio evoluciÃ³n)

    EnvÃ­a por Telegram (texto + PDF) y email (HTML premium + PDF adjunto).
    """
    try:
        logger.info("ğŸ“Š [RESUMEN DIARIO] Generando informe ejecutivo completoâ€¦")

        import requests
        from domain.services.report_service import generar_pdf_informe
        from domain.services.notification_service import (
            broadcast_alert as ns_broadcast,
            build_daily_email_html,
        )

        API_BASE = "http://localhost:8000"
        API_KEY = os.getenv(
            'API_KEY', 'mme-portal-energetico-2026-secret-key'
        )
        HDR = {"Content-Type": "application/json", "X-API-Key": API_KEY}

        def _api_call(intent, params=None, timeout=120):
            """Helper para llamar al orquestador."""
            try:
                r = requests.post(
                    f"{API_BASE}/v1/chatbot/orchestrator",
                    json={
                        "sessionId": f"daily_{intent}_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                        "intent": intent,
                        "parameters": params or {},
                    },
                    headers=HDR,
                    timeout=timeout,
                )
                if r.status_code == 200:
                    return r.json().get('data', {})
            except Exception as e:
                logger.warning(f"[RESUMEN DIARIO] Error en API {intent}: {e}")
            return {}

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # 1. Texto narrativo IA (informe_ejecutivo)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        informe_texto = None
        generado_con_ia = False
        fecha_generacion = datetime.now().strftime('%Y-%m-%d %H:%M')

        d_informe = _api_call('informe_ejecutivo')
        if d_informe:
            informe_texto = d_informe.get('informe')
            generado_con_ia = d_informe.get('generado_con_ia', False)
            fecha_generacion = d_informe.get('fecha_generacion', fecha_generacion)
            if informe_texto:
                logger.info(
                    f"[RESUMEN DIARIO] Informe IA obtenido "
                    f"({len(informe_texto)} chars, IA={generado_con_ia})"
                )

        if not informe_texto:
            logger.info("[RESUMEN DIARIO] Usando fallback de KPIs bÃ¡sicos")
            informe_texto = _build_kpi_fallback()
            generado_con_ia = False

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # 2. Datos estructurados reales
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # 2a. KPIs (estado_actual â†’ fichas)
        fichas = []
        d_estado = _api_call('estado_actual', timeout=60)
        if d_estado:
            fichas = d_estado.get('fichas', [])
            logger.info(f"[RESUMEN DIARIO] KPIs obtenidos: {len(fichas)}")

        # 2b. Predicciones a 30 dÃ­as â€” las 3 mÃ©tricas clave
        predicciones_lista = []
        _PRED_METRICS = [
            ('GENE_TOTAL', 'GeneraciÃ³n Total del Sistema'),
            ('PRECIO_BOLSA', 'Precio de Bolsa Nacional'),
            ('EMBALSES_PCT', 'Porcentaje de Embalses'),
        ]
        for metric_id, metric_label in _PRED_METRICS:
            d_pred = _api_call(
                'predicciones',
                {'fuente': metric_id, 'horizonte': 30},
                timeout=60,
            )
            if d_pred and d_pred.get('predicciones'):
                predicciones_lista.append({
                    'fuente': d_pred.get('fuente', metric_label),
                    'fuente_label': metric_label,
                    'horizonte_dias': d_pred.get('horizonte_dias', 30),
                    'estadisticas': d_pred.get('estadisticas', {}),
                    'modelo': d_pred.get('modelo', ''),
                    'conclusiones': d_pred.get('conclusiones', []),
                    'predicciones': d_pred.get('predicciones', []),
                })
                logger.info(
                    f"[RESUMEN DIARIO] Predicciones {metric_id}: "
                    f"{d_pred.get('total_predicciones', 0)} puntos"
                )
        # Compatibilidad: predicciones_data = primera mÃ©trica (o vacÃ­o)
        predicciones_data = predicciones_lista[0] if predicciones_lista else {}

        # 2c. Noticias del sector
        noticias = []
        d_news = _api_call('noticias_sector', timeout=60)
        if d_news:
            noticias = d_news.get('noticias', [])
            logger.info(f"[RESUMEN DIARIO] Noticias obtenidas: {len(noticias)}")

        # 2d. AnomalÃ­as recientes (Ãºltimas 24h desde BD)
        anomalias = []
        try:
            from infrastructure.database.manager import db_manager
            df_anom = db_manager.query_df("""
                SELECT metrica, severidad, descripcion, valor_promedio
                FROM alertas_historial
                WHERE fecha_evaluacion >= CURRENT_DATE - INTERVAL '1 day'
                ORDER BY severidad DESC, fecha_evaluacion DESC
                LIMIT 5
            """)
            if not df_anom.empty:
                anomalias = df_anom.to_dict('records')
                logger.info(f"[RESUMEN DIARIO] AnomalÃ­as recientes: {len(anomalias)}")
        except Exception as e:
            logger.warning(f"[RESUMEN DIARIO] Error leyendo anomalÃ­as: {e}")

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # 3. Generar grÃ¡ficos PNG
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        chart_paths = []
        try:
            from whatsapp_bot.services.informe_charts import generate_all_informe_charts
            charts = generate_all_informe_charts()
            for key in ('generacion', 'embalses', 'precios'):
                path = charts.get(key, (None,))[0]
                if path and os.path.isfile(path):
                    chart_paths.append(path)
            logger.info(f"[RESUMEN DIARIO] GrÃ¡ficos generados: {len(chart_paths)}")
        except Exception as e:
            logger.warning(f"[RESUMEN DIARIO] Error generando grÃ¡ficos: {e}")

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # 4. Generar PDF (narrativa + grÃ¡ficos)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        pdf_path = None
        try:
            pdf_path = generar_pdf_informe(
                informe_texto, fecha_generacion, generado_con_ia,
                chart_paths=chart_paths,
                fichas=fichas,
                predicciones=predicciones_lista or predicciones_data,
                anomalias=anomalias,
                noticias=noticias,
            )
            if pdf_path:
                size_kb = os.path.getsize(pdf_path) / 1024
                logger.info(f"[RESUMEN DIARIO] PDF generado: {pdf_path} ({size_kb:.1f} KB)")
        except Exception as e:
            logger.warning(f"[RESUMEN DIARIO] Error generando PDF: {e}")

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # 5. Construir mensaje Telegram
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        tg_message = (
            f"ğŸ“Š *INFORME EJECUTIVO DIARIO DEL SIN*\n\n"
            f"ğŸ“… Fecha: {datetime.now().strftime('%Y-%m-%d')}\n\n"
        )
        # KPIs
        if fichas:
            for f in fichas[:3]:
                emoji = f.get('emoji', 'âš¡')
                ind = f.get('indicador', '')
                val = f.get('valor', '')
                uni = f.get('unidad', '')
                ctx = f.get('contexto', {})
                var_pct = ctx.get('variacion_vs_promedio_pct', '')
                etiqueta_var = ctx.get('etiqueta_variacion', 'vs 7d')
                tend = ctx.get('tendencia', '')
                tg_message += f"{emoji} *{ind}:* {val} {uni}"
                if var_pct:
                    tg_message += f" ({var_pct:+.1f}% {etiqueta_var})" if isinstance(var_pct, (int, float)) else f" ({var_pct})"
                tg_message += "\n"
            tg_message += "\n"

        # Resumen narrativo (recortado + limpio para Telegram)
        narrative_short = _clean_markdown_for_telegram(informe_texto[:1500])
        if len(narrative_short) > 1500:
            narrative_short = narrative_short[:1497] + '...'
        tg_message += f"{narrative_short}\n\n"

        # Noticias
        if noticias:
            tg_message += "ğŸ“° *Noticias del Sector EnergÃ©tico*\n\n"
            for i, n in enumerate(noticias[:3], 1):
                titulo = n.get('titulo', 'Sin tÃ­tulo')
                fuente = n.get('fuente', '')
                url = n.get('url', '')
                resumen = n.get('resumen', n.get('resumen_corto', ''))
                if len(resumen) > 120:
                    resumen = resumen[:117] + '...'
                tg_message += f"*{i}.* {titulo}\n"
                if resumen:
                    tg_message += f"   {resumen}\n"
                if fuente:
                    tg_message += f"   _Fuente: {fuente}_\n"
                if url:
                    tg_message += f"   ğŸ”— [Leer mÃ¡s]({url})\n"
                tg_message += "\n"

        tg_message += "_Portal EnergÃ©tico â€” Ministerio de Minas y EnergÃ­a_"

        if len(tg_message) > 4000:
            tg_message = (
                tg_message[:3900] + "\n\n"
                "_(Informe recortado â€” consulte el PDF adjunto para "
                "la versiÃ³n completa)_"
            )

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # 6. Construir email HTML y enviar
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        email_html = build_daily_email_html(
            informe_texto,
            noticias=noticias,
            fichas=fichas,
            predicciones=predicciones_lista or predicciones_data,
            anomalias=anomalias,
            generado_con_ia=generado_con_ia,
        )

        result = ns_broadcast(
            message=tg_message,
            severity="INFO",
            pdf_path=pdf_path,
            email_subject=(
                f"ğŸ“Š Informe Ejecutivo del Sector ElÃ©ctrico â€” "
                f"{datetime.now().strftime('%Y-%m-%d')}"
            ),
            email_body_html=email_html,
            is_daily=True,
        )

        total_sent = (
            result.get("telegram", {}).get("sent", 0)
            + result.get("email", {}).get("sent", 0)
        )
        logger.info(
            f"ğŸ“¤ [RESUMEN DIARIO] Completado: {total_sent} notificaciones "
            f"(TG={result['telegram']['sent']}, "
            f"Email={result['email']['sent']})"
        )

        # Limpiar archivos temporales
        if pdf_path and os.path.isfile(pdf_path):
            try:
                os.remove(pdf_path)
            except OSError:
                pass
        for cp in chart_paths:
            try:
                if cp and os.path.isfile(cp):
                    os.remove(cp)
            except OSError:
                pass

        return {
            "status": "completed",
            "informe_ia": generado_con_ia,
            "telegram_sent": result["telegram"]["sent"],
            "email_sent": result["email"]["sent"],
        }

    except Exception as e:
        logger.error(
            f"âŒ [RESUMEN DIARIO] Error: {str(e)}", exc_info=True
        )
        return {"status": "error", "error": str(e)}


def _build_kpi_fallback() -> str:
    """Genera un resumen bÃ¡sico con 3 KPIs cuando el orquestador no responde."""
    from domain.services.generation_service import GenerationService
    from domain.services.hydrology_service import HydrologyService
    from domain.services.metrics_service import MetricsService

    gen_service = GenerationService()
    hydro_service = HydrologyService()
    metrics_service = MetricsService()

    end = date.today()
    start = end - timedelta(days=1)

    gen_total = 'N/D'
    try:
        df_gen = gen_service.get_daily_generation_system(start, end)
        if not df_gen.empty:
            gen_total = f"{round(df_gen['valor_gwh'].sum(), 1)} GWh"
    except Exception:
        pass

    precio = 'N/D'
    try:
        df_precio = metrics_service.get_metric_data('PrecBolsNaci', start, end)
        if not df_precio.empty:
            col = 'valor' if 'valor' in df_precio.columns else df_precio.columns[-1]
            precio = f"{round(df_precio[col].mean(), 2)} COP/kWh"
    except Exception:
        pass

    embalses = 'N/D'
    try:
        emb_data = hydro_service.get_hydrology_summary(start, end)
        if emb_data and 'porcentaje_embalses' in emb_data:
            embalses = f"{round(emb_data['porcentaje_embalses'], 1)}%"
    except Exception:
        pass

    mix_text = ""
    try:
        df_fuentes = gen_service.get_generation_by_sources(start, end)
        if not df_fuentes.empty:
            total = df_fuentes['valor_gwh'].sum()
            if total > 0:
                mix = df_fuentes.groupby('recurso')['valor_gwh'].sum()
                icons = {
                    'HidrÃ¡ulica': 'ğŸ’§', 'TÃ©rmica': 'ğŸ”¥', 'Solar': 'â˜€ï¸',
                    'EÃ³lica': 'ğŸŒ¬ï¸', 'Biomasa': 'ğŸŒ¿',
                }
                for recurso, valor in mix.sort_values(ascending=False).items():
                    pct = round((valor / total) * 100, 1)
                    icon = icons.get(recurso, 'âš¡')
                    mix_text += f"  {icon} {recurso}: {pct}%\n"
    except Exception:
        pass

    if not mix_text:
        mix_text = "  Datos de mix no disponibles\n"

    return (
        f"âš¡ *GeneraciÃ³n Total:* {gen_total}\n"
        f"ğŸ’° *Precio de Bolsa:* {precio}\n"
        f"ğŸ’§ *Embalses:* {embalses}\n\n"
        f"*Mix EnergÃ©tico:*\n{mix_text}"
    )
