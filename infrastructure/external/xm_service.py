"""Helper ligero para inicializar la conexi√≥n a pydataxm de forma perezosa (lazy).

IMPORTANTE: Sistema de cach√© ELIMINADO - Ahora usamos ETL-SQLite para datos hist√≥ricos.
La funci√≥n fetch_metric_data() consulta directamente la API XM cuando es necesario.
"""
from typing import Optional
import logging
from datetime import date, datetime, timedelta
import pandas as pd
from concurrent.futures import ThreadPoolExecutor, TimeoutError as FutureTimeoutError
import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

try:
    from pydataxm.pydataxm import ReadDB
    _PYDATAXM_AVAILABLE = True
except Exception:
    ReadDB = None
    _PYDATAXM_AVAILABLE = False

_objetoAPI = None

def get_objetoAPI():
    """Retorna una instancia √∫nica de ReadDB si est√° disponible, o None."""
    global _objetoAPI
    if _objetoAPI is not None:
        return _objetoAPI

    logger = logging.getLogger('xm_helper')
    if not _PYDATAXM_AVAILABLE:
        logger.warning('pydataxm no disponible (get_objetoAPI)')
        _objetoAPI = None
        return None

    try:
        logger.info('Iniciando conexi√≥n a API XM...')
        _objetoAPI = ReadDB()
        logger.info('‚úÖ pydataxm ReadDB inicializada correctamente')
    except Exception as e:
        logger.exception('‚ùå Error inicializando ReadDB: %s', e)
        _objetoAPI = None
    return _objetoAPI


def fetch_metric_data(metric: str, entity: str, start_date, end_date):
    """
    Consultar datos directamente desde API XM (sin cach√©).
    
    Args:
        metric: M√©trica (ej: 'PrecBolsNaci', 'Gene')
        entity: Entidad (ej: 'Sistema', 'Recurso')
        start_date: Fecha inicio
        end_date: Fecha fin
    
    Returns:
        DataFrame o None
    """
    logger = logging.getLogger('xm_helper')
    objetoAPI = get_objetoAPI()
    
    if objetoAPI is None:
        logger.warning(f'‚ùå API XM no disponible para {metric}/{entity}')
        return None
    
    try:
        logger.info(f'üîç API XM: {metric}/{entity} {start_date} a {end_date}')
        
        def _fetch():
            return objetoAPI.request_data(metric, entity, start_date, end_date)
        
        with ThreadPoolExecutor(max_workers=1) as executor:
            future = executor.submit(_fetch)
            data = future.result(timeout=30)
        
        if data is not None and not data.empty:
            logger.info(f'‚úÖ API XM: {len(data)} registros')
            return data
        else:
            logger.warning(f'‚ö†Ô∏è API XM: Sin datos')
            return None
            
    except FutureTimeoutError:
        logger.error(f'‚è±Ô∏è Timeout (30s) {metric}/{entity}')
        return None
    except Exception as e:
        logger.exception(f'‚ùå Error: {e}')
        return None


def obtener_datos_desde_bd(metric: str, entity: str, fecha_fin, dias_busqueda: int = 7, recurso: str = None):
    """
    Consultar datos desde base de datos con fallback autom√°tico hacia atr√°s.
    """
    from infrastructure.database.repositories.metrics_repository import MetricsRepository
    logger = logging.getLogger('xm_helper')
    
    if isinstance(fecha_fin, str):
        fecha_fin = datetime.strptime(fecha_fin, '%Y-%m-%d').date()
    elif isinstance(fecha_fin, datetime):
        fecha_fin = fecha_fin.date()
    
    repo = MetricsRepository()
    
    for dias_atras in range(dias_busqueda):
        fecha_inicio = fecha_fin - timedelta(days=dias_atras)
        fecha_str = fecha_inicio.strftime('%Y-%m-%d')
        
        # FIX: Usar get_metric_data_by_entity para traer columna recurso/entidad
        df = repo.get_metric_data_by_entity(
            metric_id=metric,
            entity=entity,
            start_date=fecha_str,
            end_date=fecha_str,
            resource=recurso
        )
        
        if df is not None and not df.empty:
            if dias_atras > 0:
                logger.info(f"‚úÖ [SQLite] {metric}/{entity} en {fecha_str} ({dias_atras}d atr√°s)")
            else:
                logger.info(f"‚úÖ [SQLite] {metric}/{entity} en {fecha_str}")
            
            if 'valor_gwh' in df.columns:
                df = df.rename(columns={'valor_gwh': 'Value', 'fecha': 'Date'})
            
            if 'recurso' in df.columns and df['recurso'].notna().any():
                if entity == 'Embalse':
                    df = df.rename(columns={'recurso': 'Embalse'})
                elif entity == 'Rio':
                    df = df.rename(columns={'recurso': 'Rio'})
                elif entity == 'Recurso':
                    df = df.rename(columns={'recurso': 'Resources'})
                elif entity == 'Agente':
                    df = df.rename(columns={'recurso': 'Agente'})
            
            return df, fecha_inicio
    
    logger.warning(f"‚ùå [SQLite] Sin datos {metric}/{entity} √∫ltimos {dias_busqueda}d")
    return None, None
def obtener_datos_inteligente(metric: str, entity: str, fecha_inicio, fecha_fin, recurso: str = None):
    """
    Consulta inteligente de datos: SQLite (>=2020, r√°pido) vs API XM (<2020, lento con advertencia).
    
    Esta funci√≥n decide autom√°ticamente la fuente de datos bas√°ndose en el rango de fechas:
    - Si fecha_inicio >= 2020-01-01: Consulta SQLite (r√°pido, <5s)
    - Si fecha_inicio < 2020-01-01: Consulta API XM directo (lento, 30-60s, muestra advertencia)
    
    Args:
        metric: M√©trica XM (ej: 'Gene', 'AporEner', 'VoluUtilDiarEner')
        entity: Entidad (ej: 'Sistema', 'Embalse', 'Rio', 'Recurso')
        fecha_inicio: Fecha inicial del rango (str 'YYYY-MM-DD' o date/datetime object)
        fecha_fin: Fecha final del rango (str 'YYYY-MM-DD' o date/datetime object)
        recurso: Filtro opcional por recurso (ej: 'SOLAR', 'EOLICA')
    
    Returns:
        tuple: (DataFrame con datos, str mensaje de advertencia o None)
    
    Ejemplos:
        # Consulta reciente (>= 2020) - Usa SQLite
        df, warning = obtener_datos_inteligente('Gene', 'Sistema', '2023-01-01', '2024-01-01')
        # warning = None, consulta r√°pida
        
        # Consulta hist√≥rica (< 2020) - Usa API XM
        df, warning = obtener_datos_inteligente('Gene', 'Sistema', '2015-01-01', '2016-01-01')
        # warning = "‚ö†Ô∏è Consultando datos hist√≥ricos (antes de 2020) directamente..."
    """
    from datetime import datetime, date
    from infrastructure.database.repositories.metrics_repository import MetricsRepository
    
    logger = logging.getLogger('xm_helper')
    
    # Fecha l√≠mite: datos antes del 2020 no est√°n en SQLite
    FECHA_LIMITE_SQLITE = date(2020, 1, 1)
    
    # Convertir fechas a objetos date
    if isinstance(fecha_inicio, str):
        fecha_inicio_date = datetime.strptime(fecha_inicio, '%Y-%m-%d').date()
    elif isinstance(fecha_inicio, datetime):
        fecha_inicio_date = fecha_inicio.date()
    else:
        fecha_inicio_date = fecha_inicio
    
    if isinstance(fecha_fin, str):
        fecha_fin_date = datetime.strptime(fecha_fin, '%Y-%m-%d').date()
    elif isinstance(fecha_fin, datetime):
        fecha_fin_date = fecha_fin.date()
    else:
        fecha_fin_date = fecha_fin
    
    # Convertir a strings para las consultas
    fecha_inicio_str = fecha_inicio_date.strftime('%Y-%m-%d')
    fecha_fin_str = fecha_fin_date.strftime('%Y-%m-%d')
    
    # Decisi√≥n: SQLite vs API XM
    if fecha_inicio_date >= FECHA_LIMITE_SQLITE:
        # CASO 1: Datos recientes (>= 2020) - Usar SQLite (r√°pido)
        logger.info(f"üìä [SQLite] Consultando {metric}/{entity} desde {fecha_inicio_str} hasta {fecha_fin_str}")
        
        # Para m√©tricas de nivel Sistema, usar recurso='_SISTEMA_' para evitar duplicados
        recurso_filtro = recurso
        if entity == 'Sistema' and recurso is None:
            recurso_filtro = '_SISTEMA_'
            logger.info(f"üîç [Filtro] Aplicando recurso='_SISTEMA_' para evitar datos duplicados")
        
        repo = MetricsRepository()
        df = repo.get_metric_data_by_entity(
            metric_id=metric,
            entity=entity,
            start_date=fecha_inicio_str,
            end_date=fecha_fin_str,
            resource=recurso_filtro
        )
        
        if df is not None and not df.empty:
            # Renombrar columnas para compatibilidad con c√≥digo existente
            # SQLite: fecha, metrica, entidad, recurso, valor_gwh, unidad
            # API XM: Date, Name, Value, Id
            
            if 'valor_gwh' in df.columns:
                df = df.rename(columns={'valor_gwh': 'Value'})
            
            if 'fecha' in df.columns:
                df = df.rename(columns={'fecha': 'Date'})
            
            # MAPEO DE C√ìDIGOS A NOMBRES usando tabla catalogos
            if 'recurso' in df.columns:
                # Intentar mapear c√≥digos a nombres desde cat√°logos
                catalogo_nombre = None
                if entity == 'Recurso':
                    catalogo_nombre = 'ListadoRecursos'
                elif entity == 'Embalse':
                    catalogo_nombre = 'ListadoEmbalses'
                elif entity == 'Rio':
                    catalogo_nombre = 'ListadoRios'
                elif entity == 'Agente':
                    catalogo_nombre = 'ListadoAgentes'
                
                if catalogo_nombre:
                    try:
                        # Obtener mapeo c√≥digo ‚Üí nombre
                        mapeo = repo.get_catalogue_mapping(catalogo_nombre)
                        if mapeo:
                            # Aplicar mapeo: si el c√≥digo existe en cat√°logo, usar nombre; si no, mantener c√≥digo
                            df['Name'] = df['recurso'].apply(lambda x: mapeo.get(str(x).upper(), x) if pd.notna(x) else x)
                            logger.info(f"‚úÖ [Mapeo] {len(mapeo)} c√≥digos mapeados desde {catalogo_nombre}")
                        else:
                            # Sin mapeo, usar c√≥digo tal cual
                            df['Name'] = df['recurso']
                            logger.warning(f"‚ö†Ô∏è [Mapeo] {catalogo_nombre} vac√≠o, usando c√≥digos directamente")
                    except Exception as e:
                        logger.warning(f"‚ö†Ô∏è [Mapeo] Error obteniendo {catalogo_nombre}: {e}")
                        df['Name'] = df['recurso']
                else:
                    # Sin cat√°logo, renombrar directamente
                    df['Name'] = df['recurso']
                
                # ==============================================================================
                # PARCHE DE COMPATIBILIDAD (Backend -> Frontend Legacy)
                # ==============================================================================
                # Asegurar que existan los alias que espera la UI antigua (Values_Code, Values_Name)
                
                # 1. Alias para C√≥digo
                if 'recurso' in df.columns:
                    if 'Values_Code' not in df.columns:
                        df['Values_Code'] = df['recurso']  # Alias principal
                    if 'Values_code' not in df.columns:
                        df['Values_code'] = df['recurso']  # Alias lowercase
                        
                # 2. Alias para Nombre
                if 'Name' in df.columns and 'Values_Name' not in df.columns:
                    df['Values_Name'] = df['Name']
                elif 'recurso' in df.columns and 'Values_Name' not in df.columns:
                    df['Values_Name'] = df['recurso']
                
                # 3. Alias por entidad espec√≠fica
                if entity == 'Embalse' and 'Name' in df.columns:
                    df['Embalse'] = df['Name']
                elif entity == 'Rio' and 'Name' in df.columns:
                    df['Rio'] = df['Name']
                elif entity == 'Recurso' and 'Name' in df.columns:
                    df['Resources'] = df['Name']
                elif entity == 'Agente' and 'Name' in df.columns:
                    df['Agente'] = df['Name']
            
            # VERIFICAR: Si todos los valores de Name son None, usar API como fallback
            if 'Name' in df.columns and df['Name'].isna().all():
                logger.warning(f"‚ö†Ô∏è [SQLite] Columna 'Name' vac√≠a, fallback a API XM")
                # No retornar estos datos vac√≠os, dejar que consulte API
                df = None
            
            if df is not None:
                logger.info(f"‚úÖ [SQLite] {len(df)} registros obtenidos con nombres mapeados")
                return df, None  # Sin advertencia
        
        # Si no hay datos en SQLite o est√°n incompletos, usar API XM
        logger.info(f"üì° [Fallback] Consultando API XM para {metric}/{entity}")
    
    # CASO 2: Datos hist√≥ricos (< 2020) o fallback desde SQLite
    mensaje_advertencia = None
    if fecha_inicio_date < FECHA_LIMITE_SQLITE:
        mensaje_advertencia = (
            f"‚ö†Ô∏è **Consultando datos hist√≥ricos** (antes de 2020) directamente desde API XM. "
            f"Esta operaci√≥n puede tardar 30-60 segundos..."
        )
        logger.warning(f"üêå [API XM] Consultando datos hist√≥ricos {metric}/{entity} desde {fecha_inicio_str}")
    else:
        logger.info(f"üì° [API XM] Fallback desde SQLite, consultando {metric}/{entity}")
    
    try:
        df = fetch_metric_data(
            metric=metric,
            entity=entity,
            start_date=fecha_inicio_str,
            end_date=fecha_fin_str
        )
        
        if df is not None and not df.empty:
            logger.info(f"‚úÖ [API XM] {len(df)} registros obtenidos")
            
            # POST-PROCESAMIENTO: Convertir datos horarios a valores diarios
            # Si el DF tiene columnas Values_Hour01-24 pero no 'Value', agregarlo
            hour_cols = [f'Values_Hour{i:02d}' for i in range(1, 25)]
            existing_hour_cols = [col for col in hour_cols if col in df.columns]
            
            if existing_hour_cols and 'Value' not in df.columns:
                # Detectar si es m√©trica de energ√≠a o potencia
                # P√©rdidas y Generaci√≥n: SUMAR (kWh ‚Üí GWh)
                # Disponibilidad: PROMEDIAR (kW ‚Üí MW)
                if 'Perdidas' in metric or 'Gene' in metric or 'Dema' in metric:
                    # Energ√≠a: SUMAR valores horarios en kWh ‚Üí GWh
                    df['Value'] = df[existing_hour_cols].sum(axis=1) / 1_000_000
                    logger.info(f"üîÑ [Post-procesamiento] Sumando {len(existing_hour_cols)} horas (kWh ‚Üí GWh)")
                elif 'Dispo' in metric:
                    # Potencia: PROMEDIAR valores horarios en kW ‚Üí MW
                    df['Value'] = df[existing_hour_cols].mean(axis=1) / 1_000
                    logger.info(f"üîÑ [Post-procesamiento] Promediando {len(existing_hour_cols)} horas (kW ‚Üí MW)")
                else:
                    # Por defecto: SUMAR
                    df['Value'] = df[existing_hour_cols].sum(axis=1) / 1_000_000
                    logger.info(f"üîÑ [Post-procesamiento] Sumando {len(existing_hour_cols)} horas (conversi√≥n gen√©rica)")
            
            return df, mensaje_advertencia
        else:
            logger.warning(f"‚ö†Ô∏è [API XM] No hay datos para {metric}/{entity} en el rango solicitado")
            return None, mensaje_advertencia
    
    except Exception as e:
        logger.error(f"‚ùå [API XM] Error al consultar datos: {e}")
        return None, mensaje_advertencia

def fetch_gene_recurso_chunked(start_date, end_date):
    """
    Obtiene generaci√≥n por recurso en el rango de fechas.
    Wrapper de compatibilidad.
    """
    return fetch_metric_data('Gene', 'Recurso', start_date, end_date)

class XMService:
    """Clase wrapper para compatibilidad con Clean Architecture"""
    
    METRIC_ENTITY_MAP = {
        # Precios
        'PrecBolsNaci': 'Sistema',
        'PrecBolsCTG': 'Sistema',
        'PrecEsca': 'Sistema',
        'PrecEscaAct': 'Sistema',
        'PrecEscaSup': 'Sistema',
        'PrecEscaInf': 'Sistema',
        
        # Comercializaci√≥n
        'CONTRATO': 'Sistema', 
        'LIQUIDACION': 'Sistema',
        
        # Demanda
        'DemaCome': 'Agente',
        'DemaReal': 'Agente',
        
        # Distribuci√≥n / Otros
        'TXR': 'Sistema',
        'PERCOM': 'Sistema', 
        'CONSUM': 'Sistema',
        'PERD': 'Sistema',
        'Gene': 'Recurso'
    }

    def get_metric_data(self, metric: str, start_date, end_date):
        entity = self.METRIC_ENTITY_MAP.get(metric, 'Sistema')
        return fetch_metric_data(metric, entity, start_date, end_date)
