#!/usr/bin/env python3
"""
Actualizaci√≥n incremental del ETL - Solo datos nuevos desde √∫ltima fecha en BD
Usa las MISMAS conversiones que etl_xm_to_sqlite.py
"""

import sys
import os
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

import sqlite3
from datetime import datetime, timedelta
# from utils._xm import get_objetoAPI  <-- REEMPLAZADO
from infrastructure.external.xm_service import XMService
# from utils.db_manager import upsert_metrics_bulk <-- REEMPLAZADO
from infrastructure.database.manager import DatabaseManager
import logging
import pandas as pd

logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')
logger = logging.getLogger(__name__)

# Configuraci√≥n de conversiones (debe coincidir con etl/config_metricas.py)
CONVERSION_CONFIG = {
    'VoluUtilDiarEner': 'kWh_a_GWh',  # API devuelve en kWh
    'CapaUtilDiarEner': 'kWh_a_GWh',  # API devuelve en kWh
    'AporEner': 'Wh_a_GWh',           # API devuelve en Wh
    'AporEnerMediHist': 'Wh_a_GWh',   # API devuelve en Wh
    'Gene': 'horas_a_diario',         # Sumar Values_Hour01-24 en kWh ‚Üí GWh
    'DemaCome': 'horas_a_diario'      # Sumar Values_Hour01-24 en kWh ‚Üí GWh
}

def convertir_valor(df, metrica, valor):
    """
    Convierte el valor seg√∫n el tipo de m√©trica usando las reglas del ETL original
    
    Conversiones:
    - Wh_a_GWh: Divide por 1,000,000 (no 1e9)
    - kWh_a_GWh: Divide por 1,000,000 (no 1e9)
    - horas_a_diario: Suma Values_Hour01-24 y divide por 1,000,000
    """
    conversion = CONVERSION_CONFIG.get(metrica)
    
    if conversion == 'Wh_a_GWh':
        return valor / 1_000_000  # Wh ‚Üí GWh
    elif conversion == 'kWh_a_GWh':
        return valor / 1_000_000  # kWh ‚Üí GWh
    elif conversion == 'horas_a_diario':
        # Si el DataFrame tiene columnas Values_Hour*, sumarlas
        hour_cols = [f'Values_Hour{i:02d}' for i in range(1, 25)]
        existing_cols = [col for col in hour_cols if col in df.columns]
        if existing_cols:
            # Retornar None para indicar que se debe sumar despu√©s
            return None
        else:
            # Si no hay columnas horarias, convertir el valor directo
            return valor / 1_000_000
    else:
        # Sin conversi√≥n, retornar el valor original
        return valor

DB_PATH = os.path.join(os.path.dirname(__file__), '..', 'portal_energetico.db')

def obtener_ultima_fecha(metrica, entidad):
    """Obtiene la √∫ltima fecha disponible en BD para una m√©trica"""
    try:
        conn = sqlite3.connect(DB_PATH)
        cursor = conn.cursor()
        cursor.execute("""
            SELECT MAX(fecha) FROM metrics 
            WHERE metrica = ? AND entidad = ?
        """, (metrica, entidad))
        result = cursor.fetchone()[0]
        conn.close()
        return result
    except:
        return None

def actualizar_metrica(xm_service, metrica, entidad, nombre):
    """Actualiza una m√©trica espec√≠fica desde √∫ltima fecha hasta hoy"""
    logger.info(f"\n{'='*60}")
    logger.info(f"üì° {nombre} ({metrica}/{entidad})")
    logger.info(f"{'='*60}")
    
    # Obtener √∫ltima fecha en BD
    ultima_fecha_str = obtener_ultima_fecha(metrica, entidad)
    
    if ultima_fecha_str:
        ultima_fecha = datetime.strptime(ultima_fecha_str, '%Y-%m-%d').date()
        fecha_inicio = ultima_fecha - timedelta(days=3)  # 3 d√≠as de overlap por seguridad
        logger.info(f"   √öltima fecha en BD: {ultima_fecha}")
    else:
        # Si no hay datos, traer √∫ltimos 7 d√≠as
        fecha_inicio = datetime.now().date() - timedelta(days=7)
        logger.info(f"   Sin datos previos, trayendo √∫ltimos 7 d√≠as")
    
    fecha_fin = datetime.now().date()
    
    logger.info(f"   Rango: {fecha_inicio} a {fecha_fin}")
    
    try:
        df = xm_service.request_data(
            metrica, 
            entidad,
            fecha_inicio.strftime('%Y-%m-%d'),
            fecha_fin.strftime('%Y-%m-%d')
        )
        
        if df is None or df.empty:
            logger.warning(f"   ‚ö†Ô∏è  Sin datos disponibles")
            return 0
        
        # Preparar datos para inserci√≥n
        metrics_data = []
        
        # Para m√©tricas con horas, sumar primero
        conversion = CONVERSION_CONFIG.get(metrica)
        if conversion == 'horas_a_diario':
            hour_cols = [f'Values_Hour{i:02d}' for i in range(1, 25)]
            existing_cols = [col for col in hour_cols if col in df.columns]
            
            if existing_cols:
                # Sumar todas las horas por fila
                df_processed = df.copy()
                df_processed['Value'] = df_processed[existing_cols].sum(axis=1) / 1_000_000  # kWh ‚Üí GWh
                logger.info(f"   ‚úÖ Sumadas {len(existing_cols)} horas, promedio: {df_processed['Value'].mean():.2f} GWh")
                df = df_processed
        
        for _, row in df.iterrows():
            fecha = row['Date'] if isinstance(row['Date'], str) else row['Date'].strftime('%Y-%m-%d')
            
            # Obtener valor crudo
            valor_raw = row.get('Value', 0)
            
            # Detectar recurso: priorizar Name (embalses), luego Values_code, luego _SISTEMA_
            if 'Name' in df.columns and pd.notna(row.get('Name')):
                recurso_val = row['Name']
            elif 'Values_code' in df.columns and pd.notna(row.get('Values_code')):
                recurso_val = row['Values_code']
            else:
                recurso_val = '_SISTEMA_'
            
            # Convertir usando la funci√≥n correcta
            valor_convertido = convertir_valor(df, metrica, valor_raw)
            
            # Si la funci√≥n retorna None, significa que ya se proces√≥ en el paso anterior
            if valor_convertido is None:
                valor_convertido = valor_raw  # Ya est√° convertido en el DataFrame
            
            metrics_data.append((fecha, metrica, entidad, recurso_val, valor_convertido, 'GWh'))
        
        # Insertar en BD
        db = DatabaseManager()
        registros = db.upsert_metrics_bulk(metrics_data)
        logger.info(f"   ‚úÖ {registros} registros actualizados")
        
        # Mostrar rango de fechas actualizado
        if 'Date' in df.columns:
            fecha_min = df['Date'].min()
            fecha_max = df['Date'].max()
            logger.info(f"   üìÖ Rango actualizado: {fecha_min} a {fecha_max}")
        
        return registros
        
    except Exception as e:
        logger.error(f"   ‚ùå Error: {e}")
        return 0

def main():
    print("[DEBUG] INICIO main()")
    logger.info("\n" + "="*60)
    logger.info("‚ö° ACTUALIZACI√ìN INCREMENTAL - SOLO DATOS NUEVOS")
    logger.info("‚öôÔ∏è  Usando conversiones del ETL original:")
    logger.info("   ‚Ä¢ Wh ‚Üí GWh: √∑ 1,000,000")
    logger.info("   ‚Ä¢ kWh ‚Üí GWh: √∑ 1,000,000")
    logger.info("   ‚Ä¢ Horas ‚Üí Diario: Sumar 24 horas")
    logger.info("="*60)
    logger.info(f"Inicio: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")

    print("[DEBUG] Antes de XMService()")
    api = XMService()
    print("[DEBUG] Despu√©s de XMService()")

    metricas = [
        ('VoluUtilDiarEner', 'Embalse', 'Volumen √ötil Diario (kWh‚ÜíGWh)'),
        ('CapaUtilDiarEner', 'Embalse', 'Capacidad √ötil Diario (kWh‚ÜíGWh)'),
        ('AporEner', 'Sistema', 'Aportes Energ√≠a Sistema (Wh‚ÜíGWh)'),
        ('AporEnerMediHist', 'Sistema', 'Aportes Media Hist√≥rica (Wh‚ÜíGWh)'),
        ('Gene', 'Sistema', 'Generaci√≥n Sistema (24h‚ÜíGWh)'),
        ('DemaCome', 'Sistema', 'Demanda Comercial (24h‚ÜíGWh)'),
    ]

    total_registros = 0
    for metrica, entidad, nombre in metricas:
        print(f"[DEBUG] Actualizando {metrica} / {entidad}")
        registros = actualizar_metrica(api, metrica, entidad, nombre)
        print(f"[DEBUG] Registros actualizados para {metrica}: {registros}")
        total_registros += registros

    logger.info("\n" + "="*60)
    logger.info(f"‚úÖ ACTUALIZACI√ìN COMPLETADA")
    logger.info(f"Total registros actualizados: {total_registros}")
    logger.info(f"Fin: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    logger.info("="*60)
    
    # Auto-correcci√≥n autom√°tica despu√©s de cada actualizaci√≥n
    logger.info("\n" + "="*60)
    logger.info("üîß INICIANDO AUTO-CORRECCI√ìN POST-ACTUALIZACI√ìN")
    logger.info("‚ö†Ô∏è Auto-correcci√≥n deshabilitada temporalmente (m√≥dulo en legacy_archive)")
    logger.info("="*60)
    
    # try:
    #     # Importar y ejecutar auto-correcci√≥n
    #     from autocorreccion import AutoCorrector
    #     corrector = AutoCorrector(db_path=DB_PATH, dry_run=False)
    #     exito = corrector.ejecutar_todo()
    #     
    #     if exito:
    #         logger.info("‚úÖ Auto-correcci√≥n completada exitosamente")
    #     else:
    #         logger.warning("‚ö†Ô∏è Auto-correcci√≥n completada con advertencias")
    # except Exception as e:
    #     logger.error(f"‚ùå Error en auto-correcci√≥n: {e}")
    #     logger.info("‚ö†Ô∏è Continuando sin auto-correcci√≥n (actualizaci√≥n fue exitosa)")

if __name__ == '__main__':
    main()
