# üèóÔ∏è PLAN DE REFACTORIZACI√ìN ARQUITECT√ìNICA
## Portal Energ√©tico MME - Transformaci√≥n a Arquitectura Empresarial

**Fecha:** 28 de enero de 2026  
**Ingeniero:** Sistema de Refactorizaci√≥n Automatizada  
**Objetivo:** Transformar proyecto monol√≠tico a arquitectura modular, escalable y lista para APIs

---

## üìã TABLA DE CONTENIDOS

1. [An√°lisis de Estructura Actual](#an√°lisis-estructura-actual)
2. [Problemas Identificados](#problemas-identificados)
3. [Estructura Propuesta (Target)](#estructura-propuesta-target)
4. [Plan de Migraci√≥n por Fases](#plan-de-migraci√≥n-por-fases)
5. [Refactorizaci√≥n de C√≥digo](#refactorizaci√≥n-de-c√≥digo)
6. [Limpieza de Archivos](#limpieza-de-archivos)
7. [Mejoras de Infraestructura](#mejoras-de-infraestructura)
8. [Sistema ETL y ML](#sistema-etl-y-ml)
9. [Criterios de Calidad](#criterios-de-calidad)
10. [Plan de Pruebas](#plan-de-pruebas)

---

## üìä AN√ÅLISIS DE ESTRUCTURA ACTUAL

### Estructura Existente (Simplificada)

```
server/
‚îú‚îÄ‚îÄ app.py                          # 206 l√≠neas - Punto de entrada monol√≠tico
‚îú‚îÄ‚îÄ gunicorn_config.py             # Configuraci√≥n Gunicorn
‚îú‚îÄ‚îÄ dashboard-mme.service          # Systemd service
‚îú‚îÄ‚îÄ nginx-dashboard.conf           # Nginx config
‚îú‚îÄ‚îÄ requirements.txt               # Dependencias
‚îÇ
‚îú‚îÄ‚îÄ pages/                         # 21 m√≥dulos Dash (p√°ginas del dashboard)
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ index_simple_working.py   # Portada
‚îÇ   ‚îú‚îÄ‚îÄ generacion.py             # Generaci√≥n general
‚îÇ   ‚îú‚îÄ‚îÄ generacion_fuentes_unificado.py
‚îÇ   ‚îú‚îÄ‚îÄ generacion_hidraulica_hidrologia.py
‚îÇ   ‚îú‚îÄ‚îÄ transmision.py
‚îÇ   ‚îú‚îÄ‚îÄ distribucion.py
‚îÇ   ‚îú‚îÄ‚îÄ distribucion_demanda_unificado.py
‚îÇ   ‚îú‚îÄ‚îÄ comercializacion.py
‚îÇ   ‚îú‚îÄ‚îÄ perdidas.py
‚îÇ   ‚îú‚îÄ‚îÄ restricciones.py
‚îÇ   ‚îú‚îÄ‚îÄ metricas.py
‚îÇ   ‚îú‚îÄ‚îÄ components.py             # ‚ö†Ô∏è Componentes mezclados con p√°ginas
‚îÇ   ‚îú‚îÄ‚îÄ config.py                 # ‚ö†Ô∏è Config mezclada con p√°ginas
‚îÇ   ‚îú‚îÄ‚îÄ data_loader.py            # ‚ö†Ô∏è L√≥gica de negocio en carpeta UI
‚îÇ   ‚îî‚îÄ‚îÄ utils_xm.py               # ‚ö†Ô∏è Duplicaci√≥n con utils/_xm.py
‚îÇ
‚îú‚îÄ‚îÄ componentes/                   # 1 componente (chat IA)
‚îÇ   ‚îú‚îÄ‚îÄ chat_ia.py                # 525 l√≠neas - UI + l√≥gica mezcladas
‚îÇ   ‚îî‚îÄ‚îÄ __pycache__/
‚îÇ
‚îú‚îÄ‚îÄ utils/                         # 8 utilidades mezcladas
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ db_manager.py             # 679 l√≠neas - Conexi√≥n SQLite
‚îÇ   ‚îú‚îÄ‚îÄ health_check.py           # 195 l√≠neas - Health endpoint
‚îÇ   ‚îú‚îÄ‚îÄ logger.py                 # Configuraci√≥n logging
‚îÇ   ‚îú‚îÄ‚îÄ ai_agent.py               # 451 l√≠neas - Agente IA con GROQ
‚îÇ   ‚îú‚îÄ‚îÄ _xm.py                    # Cliente API XM
‚îÇ   ‚îú‚îÄ‚îÄ ml_predictor.py           # Predicciones ML
‚îÇ   ‚îî‚îÄ‚îÄ data_utils.py             # Helpers generales
‚îÇ
‚îú‚îÄ‚îÄ etl/                          # Sistema ETL
‚îÇ   ‚îú‚îÄ‚îÄ etl_xm_to_sqlite.py      # 660 l√≠neas - ETL principal
‚îÇ   ‚îú‚îÄ‚îÄ config_metricas.py       # 93 m√©tricas configuradas
‚îÇ   ‚îú‚îÄ‚îÄ validaciones.py          # Validaciones post-ETL
‚îÇ   ‚îî‚îÄ‚îÄ __pycache__/
‚îÇ
‚îú‚îÄ‚îÄ assets/                       # Frontend assets
‚îÇ   ‚îú‚îÄ‚îÄ animations.css
‚îÇ   ‚îú‚îÄ‚îÄ chat-ia.css
‚îÇ   ‚îú‚îÄ‚îÄ mme-corporate.css
‚îÇ   ‚îú‚îÄ‚îÄ professional-style.css
‚îÇ   ‚îú‚îÄ‚îÄ *.js                     # Scripts JS sueltos
‚îÇ   ‚îî‚îÄ‚îÄ images/                  # Im√°genes corporativas
‚îÇ
‚îú‚îÄ‚îÄ docs/                        # Documentaci√≥n (ya organizada en Fase 1)
‚îÇ   ‚îú‚îÄ‚îÄ analisis_historicos/
‚îÇ   ‚îú‚îÄ‚îÄ informes_mensuales/
‚îÇ   ‚îú‚îÄ‚îÄ tecnicos/
‚îÇ   ‚îî‚îÄ‚îÄ referencias/
‚îÇ
‚îú‚îÄ‚îÄ logs/                        # Logs (limpiados en Fase 1)
‚îÇ   ‚îú‚îÄ‚îÄ gunicorn_*.log
‚îÇ   ‚îú‚îÄ‚îÄ etl/
‚îÇ   ‚îî‚îÄ‚îÄ validaciones/
‚îÇ
‚îú‚îÄ‚îÄ scripts/                     # Scripts diversos (organizado en Fase 1)
‚îÇ   ‚îú‚îÄ‚îÄ utilidades/
‚îÇ   ‚îî‚îÄ‚îÄ analisis_historico/
‚îÇ
‚îú‚îÄ‚îÄ tests/                       # Tests m√≠nimos
‚îÇ   ‚îî‚îÄ‚îÄ verificaciones/
‚îÇ
‚îú‚îÄ‚îÄ backups/                     # Backups BD (organizado en Fase 1)
‚îÇ   ‚îî‚îÄ‚îÄ database/
‚îÇ
‚îú‚îÄ‚îÄ config/                      # Configs (creado en Fase 3)
‚îÇ   ‚îî‚îÄ‚îÄ logrotate.conf
‚îÇ
‚îú‚îÄ‚îÄ notebooks/                   # Notebooks Jupyter (legacy)
‚îÇ   ‚îú‚îÄ‚îÄ fuente_*.ipynb
‚îÇ   ‚îî‚îÄ‚îÄ metricas_repl.ipynb
‚îÇ
‚îú‚îÄ‚îÄ legacy/                      # C√≥digo legacy archivado
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îÇ
‚îú‚îÄ‚îÄ backup_originales/           # ‚ö†Ô∏è Archivos legacy sueltos
‚îú‚îÄ‚îÄ siea/                        # ‚ö†Ô∏è Sistema SIEA (sin usar?)
‚îú‚îÄ‚îÄ sql/                         # Schemas SQL
‚îî‚îÄ‚îÄ api-energia/                 # ‚ö†Ô∏è API Node.js separada (desacoplada?)
```

---

## ‚ö†Ô∏è PROBLEMAS IDENTIFICADOS

### üî¥ Cr√≠ticos (Arquitectura)

1. **Monolito en app.py**
   - 206 l√≠neas mezclando configuraci√≥n, inicializaci√≥n, health check, routes
   - Imports de todas las p√°ginas hardcodeados
   - No hay separaci√≥n entre config, app factory, y server

2. **Mezcla de responsabilidades en `/pages`**
   - `components.py` y `config.py` NO deber√≠an estar en pages/
   - `data_loader.py` es l√≥gica de negocio, no UI
   - `utils_xm.py` duplica funcionalidad de `utils/_xm.py`

3. **Componentes sin separaci√≥n UI/L√≥gica**
   - `componentes/chat_ia.py` (525 l√≠neas) mezcla HTML/Dash + callbacks + l√≥gica
   - `utils/ai_agent.py` tiene l√≥gica de IA pero est√° en "utils"

4. **ETL sin capa de servicios**
   - `etl/etl_xm_to_sqlite.py` (660 l√≠neas) hace todo directamente
   - No hay abstracci√≥n entre ETL y DB
   - Validaciones separadas pero no integradas

5. **Utils como caj√≥n de sastre**
   - `utils/` tiene desde DB hasta ML hasta logging
   - No hay organizaci√≥n clara por dominio

6. **Sin preparaci√≥n para APIs**
   - No hay capa de servicios reutilizable
   - L√≥gica acoplada a Dash (callbacks)
   - Imposible reutilizar para REST API

### üü° Importantes (C√≥digo)

7. **Falta tipado est√°tico**
   - Pocas type hints en funciones cr√≠ticas
   - Dificulta mantenimiento y refactoring

8. **Logging inconsistente**
   - Algunos m√≥dulos usan logging, otros print()
   - No hay estructura de logs unificada

9. **Configuraci√≥n dispersa**
   - .env en ra√≠z, config.py en pages/, constantes hardcodeadas
   - Falta un config/ centralizado

10. **Tests m√≠nimos**
    - Solo tests/verificaciones/ con scripts b√°sicos
    - Sin unit tests, sin integration tests

### üü¢ Menores (Limpieza)

11. **Archivos legacy**
    - `backup_originales/` con generadores antiguos
    - `notebooks/` con experimentos no documentados
    - `siea/` sin uso claro
    - `api-energia/` desacoplada (Node.js)

12. **Duplicaci√≥n de assets**
    - Varios CSS/JS que podr√≠an consolidarse
    - Im√°genes sin optimizar

13. **Cache Python residual**
    - A√∫n 66 archivos .pyc (de 11,850 iniciales)
    - __pycache__ en varios lugares

---

## üéØ ESTRUCTURA PROPUESTA (TARGET)

### Arquitectura Clean/Hexagonal Adaptada

```
server/
‚îÇ
‚îú‚îÄ‚îÄ üìÑ app.py                      # 30 l√≠neas - Solo inicializaci√≥n
‚îú‚îÄ‚îÄ üìÑ wsgi.py                     # Entry point para Gunicorn
‚îú‚îÄ‚îÄ üìÑ requirements.txt
‚îú‚îÄ‚îÄ üìÑ .env                        # Variables de entorno
‚îú‚îÄ‚îÄ üìÑ .env.example                # Template para .env
‚îú‚îÄ‚îÄ üìÑ README.md                   # Documentaci√≥n principal
‚îÇ
‚îú‚îÄ‚îÄ üèóÔ∏è core/                       # ‚≠ê NUEVO - N√∫cleo de la aplicaci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ app_factory.py            # Factory de Dash app
‚îÇ   ‚îú‚îÄ‚îÄ config.py                 # Configuraci√≥n centralizada
‚îÇ   ‚îú‚îÄ‚îÄ constants.py              # Constantes del sistema
‚îÇ   ‚îú‚îÄ‚îÄ exceptions.py             # Excepciones personalizadas
‚îÇ   ‚îî‚îÄ‚îÄ middleware.py             # Middlewares (logging, auth futuro)
‚îÇ
‚îú‚îÄ‚îÄ üé® presentation/               # ‚≠ê NUEVO - Capa de presentaci√≥n (UI)
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ pages/                    # P√°ginas Dash (solo UI + callbacks)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ index.py             # Portada
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ generacion/          # M√≥dulo generaci√≥n
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ general.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ fuentes.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ hidrologia.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ transmision/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ transmision.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ distribucion/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ distribucion.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ demanda.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ comercializacion/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ comercializacion.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ perdidas/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ perdidas.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ restricciones/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ restricciones.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ metricas/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ metricas.py
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ components/               # Componentes reutilizables
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ navbar.py            # Navbar com√∫n
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ footer.py            # Footer
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ charts.py            # Gr√°ficos reutilizables
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tables.py            # Tablas reutilizables
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ cards.py             # Cards/KPIs
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ filters.py           # Filtros de fecha/entidad
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ chat/                # Chat IA modularizado
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ ui.py            # UI del chat
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ callbacks.py     # Callbacks del chat
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ layouts/                  # Layouts base
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îú‚îÄ‚îÄ main_layout.py       # Layout principal con navbar
‚îÇ       ‚îî‚îÄ‚îÄ page_layout.py       # Layout base para p√°ginas
‚îÇ
‚îú‚îÄ‚îÄ üß† domain/                     # ‚≠ê NUEVO - L√≥gica de negocio (Domain)
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ models/                   # Modelos de dominio (dataclasses/Pydantic)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ metric.py            # Modelo Metrica
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ prediction.py        # Modelo Predicci√≥n
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ catalog.py           # Modelo Cat√°logo
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ health.py            # Modelo Health Check
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ services/                 # Servicios de dominio (l√≥gica de negocio)
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îú‚îÄ‚îÄ metrics_service.py   # Operaciones sobre m√©tricas
‚îÇ       ‚îú‚îÄ‚îÄ predictions_service.py  # Operaciones ML
‚îÇ       ‚îú‚îÄ‚îÄ catalog_service.py   # Gesti√≥n cat√°logos
‚îÇ       ‚îú‚îÄ‚îÄ ai_service.py        # Servicio de IA (chat, an√°lisis)
‚îÇ       ‚îî‚îÄ‚îÄ health_service.py    # Health checks
‚îÇ
‚îú‚îÄ‚îÄ üîå infrastructure/             # ‚≠ê NUEVO - Infraestructura (adaptadores)
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ database/                 # Capa de persistencia
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ connection.py        # Conexi√≥n DB (pool, context managers)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ repositories/        # Repositorios (patr√≥n Repository)
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base_repository.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ metrics_repository.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ predictions_repository.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ catalog_repository.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ migrations/          # Migraciones (Alembic futuro)
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ schema.sql
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ models.py            # SQLAlchemy models (ORM)
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ external/                 # Integraciones externas
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ xm_client.py         # Cliente API XM (pydataxm)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ groq_client.py       # Cliente GROQ API
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ openrouter_client.py # Cliente OpenRouter
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ ml/                       # Machine Learning
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ models/              # Modelos ML
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ prophet_model.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sarima_model.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ensemble_model.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ training/            # Entrenamiento
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ trainer.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ evaluator.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ inference/           # Inferencia
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ predictor.py
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ etl/                      # ETL pipeline
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îú‚îÄ‚îÄ pipeline.py          # Orquestador ETL
‚îÇ       ‚îú‚îÄ‚îÄ extractors/          # Extractores
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ xm_extractor.py
‚îÇ       ‚îú‚îÄ‚îÄ transformers/        # Transformadores
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ unit_converter.py
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ data_cleaner.py
‚îÇ       ‚îú‚îÄ‚îÄ loaders/             # Cargadores
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ db_loader.py
‚îÇ       ‚îú‚îÄ‚îÄ validators/          # Validadores
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ data_validator.py
‚îÇ       ‚îî‚îÄ‚îÄ config/              # Config ETL
‚îÇ           ‚îú‚îÄ‚îÄ __init__.py
‚îÇ           ‚îî‚îÄ‚îÄ metrics_config.py
‚îÇ
‚îú‚îÄ‚îÄ üõ†Ô∏è shared/                     # ‚≠ê NUEVO - C√≥digo compartido
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ logging/                  # Logging unificado
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ logger.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ formatters.py
‚îÇ   ‚îú‚îÄ‚îÄ utils/                    # Utilidades generales
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ date_utils.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ text_utils.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ number_utils.py
‚îÇ   ‚îî‚îÄ‚îÄ decorators/               # Decoradores √∫tiles
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îú‚îÄ‚îÄ retry.py
‚îÇ       ‚îî‚îÄ‚îÄ cache.py
‚îÇ
‚îú‚îÄ‚îÄ üåê api/                        # ‚≠ê NUEVO - API REST (futuro)
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ main.py                   # FastAPI app
‚îÇ   ‚îú‚îÄ‚îÄ routes/                   # Endpoints
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ metrics.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ predictions.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ health.py
‚îÇ   ‚îú‚îÄ‚îÄ schemas/                  # Pydantic schemas
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ metric_schema.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ prediction_schema.py
‚îÇ   ‚îî‚îÄ‚îÄ dependencies.py           # FastAPI dependencies
‚îÇ
‚îú‚îÄ‚îÄ üß™ tests/                      # Tests organizados
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ unit/                     # Tests unitarios
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_services/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_repositories/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test_utils/
‚îÇ   ‚îú‚îÄ‚îÄ integration/              # Tests de integraci√≥n
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_etl/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test_api/
‚îÇ   ‚îú‚îÄ‚îÄ e2e/                      # Tests end-to-end
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ fixtures/                 # Fixtures de prueba
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ sample_data.py
‚îÇ   ‚îî‚îÄ‚îÄ conftest.py               # Configuraci√≥n pytest
‚îÇ
‚îú‚îÄ‚îÄ üìÅ deployment/                 # ‚≠ê NUEVO - Deployment configs
‚îÇ   ‚îú‚îÄ‚îÄ gunicorn_config.py
‚îÇ   ‚îú‚îÄ‚îÄ nginx.conf
‚îÇ   ‚îú‚îÄ‚îÄ systemd/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ dashboard-mme.service
‚îÇ   ‚îú‚îÄ‚îÄ docker/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ docker-compose.yml
‚îÇ   ‚îî‚îÄ‚îÄ scripts/
‚îÇ       ‚îú‚îÄ‚îÄ deploy.sh
‚îÇ       ‚îú‚îÄ‚îÄ backup.sh
‚îÇ       ‚îî‚îÄ‚îÄ restore.sh
‚îÇ
‚îú‚îÄ‚îÄ üìÅ assets/                     # Assets frontend (limpiados)
‚îÇ   ‚îú‚îÄ‚îÄ css/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.css             # CSS principal consolidado
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ components.css       # CSS componentes
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ themes.css           # Temas/variables
‚îÇ   ‚îú‚îÄ‚îÄ js/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.js              # JS principal
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ animations.js        # Animaciones
‚îÇ   ‚îî‚îÄ‚îÄ images/
‚îÇ       ‚îú‚îÄ‚îÄ logos/
‚îÇ       ‚îî‚îÄ‚îÄ icons/
‚îÇ
‚îú‚îÄ‚îÄ üìÅ docs/                       # Documentaci√≥n (ya organizada)
‚îÇ   ‚îú‚îÄ‚îÄ architecture/             # ‚≠ê NUEVO
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ README.md
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ architecture_decision_records/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ diagrams/
‚îÇ   ‚îú‚îÄ‚îÄ api/                      # ‚≠ê NUEVO
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ openapi.yaml
‚îÇ   ‚îú‚îÄ‚îÄ deployment/               # Despliegue
‚îÇ   ‚îú‚îÄ‚îÄ user_guides/              # Gu√≠as de usuario
‚îÇ   ‚îî‚îÄ‚îÄ developer_guides/         # Gu√≠as de desarrollo
‚îÇ
‚îú‚îÄ‚îÄ üìÅ scripts/                    # Scripts de mantenimiento
‚îÇ   ‚îú‚îÄ‚îÄ maintenance/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ cleanup_logs.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ backup_db.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ vacuum_db.py
‚îÇ   ‚îú‚îÄ‚îÄ migration/                # Scripts de migraci√≥n
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ migrate_to_new_structure.py
‚îÇ   ‚îî‚îÄ‚îÄ monitoring/
‚îÇ       ‚îî‚îÄ‚îÄ health_monitor.py
‚îÇ
‚îú‚îÄ‚îÄ üìÅ logs/                       # Logs (con logrotate)
‚îÇ   ‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ etl/
‚îÇ   ‚îú‚îÄ‚îÄ ml/
‚îÇ   ‚îî‚îÄ‚îÄ api/
‚îÇ
‚îú‚îÄ‚îÄ üìÅ data/                       # Datos auxiliares
‚îÇ   ‚îú‚îÄ‚îÄ cache/                    # Cache de datos
‚îÇ   ‚îî‚îÄ‚îÄ exports/                  # Exportaciones
‚îÇ
‚îú‚îÄ‚îÄ üìÅ backups/                    # Backups
‚îÇ   ‚îî‚îÄ‚îÄ database/
‚îÇ
‚îî‚îÄ‚îÄ üìÑ portal_energetico.db        # Base de datos SQLite (root por ahora)
```

---

## üöÄ PLAN DE MIGRACI√ìN POR FASES

### FASE 4: Reestructuraci√≥n de Carpetas (2 horas)

**Objetivo:** Crear nueva estructura sin romper funcionalidad actual

#### 4.1 Crear estructura nueva (sin mover archivos a√∫n)

```bash
# Crear directorios principales
mkdir -p core presentation domain infrastructure shared api tests/unit tests/integration deployment

# Crear subdirectorios presentation
mkdir -p presentation/pages presentation/components presentation/layouts

# Crear subdirectorios domain
mkdir -p domain/models domain/services

# Crear subdirectorios infrastructure
mkdir -p infrastructure/database/repositories infrastructure/external infrastructure/ml/{models,training,inference} infrastructure/etl/{extractors,transformers,loaders,validators,config}

# Crear subdirectorios shared
mkdir -p shared/logging shared/utils shared/decorators

# Crear subdirectorios api
mkdir -p api/routes api/schemas

# Crear subdirectorios deployment
mkdir -p deployment/systemd deployment/docker deployment/scripts

# Crear subdirectorios docs nuevos
mkdir -p docs/architecture/architecture_decision_records docs/architecture/diagrams docs/api

# Limpiar assets
mkdir -p assets/css assets/js assets/images/{logos,icons}
```

#### 4.2 Archivos a mantener en su ubicaci√≥n actual (temporalmente)

- ‚úÖ `app.py` - Se refactorizar√°, pero sigue siendo entry point
- ‚úÖ `portal_energetico.db` - En ra√≠z hasta migraci√≥n
- ‚úÖ `requirements.txt` - En ra√≠z
- ‚úÖ `.env` - En ra√≠z (agregar .env.example)
- ‚úÖ `logs/` - Estructura ya limpia
- ‚úÖ `backups/` - Ya organizado

#### 4.3 Archivos a mover en Fase 4

**De `pages/` a `presentation/pages/`:**
- ‚úÖ Todos los `*_page.py` (renombrados despu√©s)
- ‚ùå `components.py` ‚Üí mover a `presentation/components/`
- ‚ùå `config.py` ‚Üí mover a `core/config.py`
- ‚ùå `data_loader.py` ‚Üí refactorizar a `domain/services/`
- ‚ùå `utils_xm.py` ‚Üí eliminar (duplicado)

**De `componentes/` a `presentation/components/`:**
- ‚úÖ `chat_ia.py` ‚Üí refactorizar a `chat/` modularizado

**De `utils/` a nuevas ubicaciones:**
- `db_manager.py` ‚Üí `infrastructure/database/connection.py`
- `health_check.py` ‚Üí `domain/services/health_service.py`
- `logger.py` ‚Üí `shared/logging/logger.py`
- `ai_agent.py` ‚Üí `domain/services/ai_service.py`
- `_xm.py` ‚Üí `infrastructure/external/xm_client.py`
- `ml_predictor.py` ‚Üí `infrastructure/ml/inference/predictor.py`
- `data_utils.py` ‚Üí `shared/utils/` (dividir por tipo)

**De `etl/` a `infrastructure/etl/`:**
- `etl_xm_to_sqlite.py` ‚Üí refactorizar en `pipeline.py` + extractors/transformers/loaders
- `config_metricas.py` ‚Üí `infrastructure/etl/config/metrics_config.py`
- `validaciones.py` ‚Üí `infrastructure/etl/validators/data_validator.py`

**Deployment:**
- `gunicorn_config.py` ‚Üí `deployment/gunicorn_config.py`
- `dashboard-mme.service` ‚Üí `deployment/systemd/dashboard-mme.service`
- `nginx-dashboard.conf` ‚Üí `deployment/nginx.conf`
- Scripts de `scripts/utilidades/` ‚Üí `deployment/scripts/`

#### 4.4 Archivos a archivar o eliminar

**Archivar a `legacy/`:**
- ‚úÖ `backup_originales/` ‚Üí `legacy/backup_originales/`
- ‚úÖ `notebooks/` (despu√©s de revisi√≥n) ‚Üí `legacy/notebooks/`
- ‚ö†Ô∏è `siea/` (revisar uso primero) ‚Üí `legacy/siea/` si no se usa
- ‚ö†Ô∏è `api-energia/` (revisar relaci√≥n) ‚Üí puede quedar separada

**Eliminar completamente:**
- ‚ùå `pages/utils_xm.py` (duplicado de utils/_xm.py)
- ‚ùå `__pycache__/` residuales (66 archivos)
- ‚ùå Assets CSS/JS no usados (consolidar)

---

### FASE 5: Refactorizaci√≥n de C√≥digo (8 horas)

**Objetivo:** Migrar c√≥digo a nueva arquitectura con separaci√≥n de concerns

#### 5.1 Core - Configuraci√≥n y App Factory (1 hora)

**Crear `core/config.py`:**
```python
"""Configuraci√≥n centralizada del sistema"""
from pydantic import BaseSettings
from functools import lru_cache

class Settings(BaseSettings):
    # App
    APP_NAME: str = "Portal Energ√©tico MME"
    DEBUG: bool = False
    PORT: int = 8050
    HOST: str = "0.0.0.0"
    
    # Database
    DATABASE_PATH: str = "portal_energetico.db"
    DATABASE_TIMEOUT: float = 10.0
    
    # API XM
    XM_API_TIMEOUT: int = 30
    XM_API_RETRIES: int = 3
    
    # AI
    GROQ_API_KEY: str
    OPENROUTER_API_KEY: str
    AI_MODEL: str = "llama-3.3-70b-versatile"
    
    # ML
    ML_FORECAST_DAYS: int = 90
    ML_RETRAIN_HOURS: int = 168  # Semanal
    
    # Logging
    LOG_LEVEL: str = "INFO"
    LOG_FORMAT: str = "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
    
    class Config:
        env_file = ".env"
        case_sensitive = True

@lru_cache()
def get_settings() -> Settings:
    return Settings()
```

**Crear `core/app_factory.py`:**
```python
"""Factory de aplicaci√≥n Dash"""
import dash
import dash_bootstrap_components as dbc
from dash import Dash

from core.config import get_settings
from shared.logging import get_logger
from presentation.layouts.main_layout import create_main_layout

logger = get_logger(__name__)
settings = get_settings()

def create_app() -> Dash:
    """
    Factory de aplicaci√≥n Dash
    
    Returns:
        Aplicaci√≥n Dash configurada
    """
    logger.info("="*70)
    logger.info(f"Inicializando {settings.APP_NAME}")
    logger.info("="*70)
    
    # Crear app Dash
    app = Dash(
        __name__,
        use_pages=True,
        external_stylesheets=[
            dbc.themes.BOOTSTRAP,
            "https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700;800&display=swap",
            "https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css",
            "/assets/css/main.css",
        ],
        suppress_callback_exceptions=True
    )
    
    # Configurar layout
    app.layout = create_main_layout()
    
    # Registrar health check
    _register_health_check(app.server)
    
    logger.info(f"‚úÖ App creada - Puerto: {settings.PORT}")
    
    return app

def _register_health_check(server):
    """Registra endpoint de health check"""
    from flask import jsonify
    from domain.services.health_service import check_system_health
    
    @server.route('/health')
    def health():
        health_status = check_system_health()
        status_code = 200 if health_status['status'] in ['healthy', 'degraded'] else 503
        return jsonify(health_status), status_code
```

**Refactorizar `app.py` (de 206 ‚Üí 30 l√≠neas):**
```python
"""
Portal Energ√©tico MME
Entry point de la aplicaci√≥n
"""
from core.app_factory import create_app
from core.config import get_settings

settings = get_settings()
app = create_app()
server = app.server

if __name__ == "__main__":
    app.run(
        debug=settings.DEBUG,
        host=settings.HOST,
        port=settings.PORT
    )
```

**Crear `wsgi.py` (para Gunicorn):**
```python
"""WSGI entry point para Gunicorn"""
from app import server as application

# Gunicorn usar√°: gunicorn wsgi:application -c deployment/gunicorn_config.py
```

#### 5.2 Domain - Modelos y Servicios (2 horas)

**Crear `domain/models/metric.py`:**
```python
"""Modelo de dominio: M√©trica energ√©tica"""
from dataclasses import dataclass
from datetime import date
from typing import Optional

@dataclass
class Metric:
    """M√©trica energ√©tica"""
    fecha: date
    metrica: str
    entidad: str
    recurso: Optional[str]
    valor_gwh: float
    unidad: str
    fecha_actualizacion: date
    
    def to_dict(self) -> dict:
        """Convertir a diccionario"""
        return {
            'fecha': self.fecha.isoformat(),
            'metrica': self.metrica,
            'entidad': self.entidad,
            'recurso': self.recurso,
            'valor_gwh': self.valor_gwh,
            'unidad': self.unidad,
            'fecha_actualizacion': self.fecha_actualizacion.isoformat()
        }
```

**Crear `domain/services/metrics_service.py`:**
```python
"""Servicio de dominio: M√©tricas energ√©ticas"""
from datetime import date
from typing import List, Optional
import pandas as pd

from domain.models.metric import Metric
from infrastructure.database.repositories.metrics_repository import MetricsRepository
from shared.logging import get_logger

logger = get_logger(__name__)

class MetricsService:
    """Servicio para operaciones con m√©tricas"""
    
    def __init__(self, repository: MetricsRepository):
        self.repository = repository
    
    def get_metrics(
        self,
        metrica: str,
        entidad: str,
        fecha_inicio: date,
        fecha_fin: Optional[date] = None,
        recurso: Optional[str] = None
    ) -> pd.DataFrame:
        """
        Obtener m√©tricas del sistema
        
        Args:
            metrica: C√≥digo de m√©trica ('Gene', 'DemaCome', etc.)
            entidad: Entidad ('Sistema', 'Recurso', etc.)
            fecha_inicio: Fecha inicial
            fecha_fin: Fecha final (opcional)
            recurso: Filtro por recurso (opcional)
            
        Returns:
            DataFrame con m√©tricas
        """
        logger.info(f"Obteniendo m√©tricas: {metrica}, {entidad}, {fecha_inicio}-{fecha_fin}")
        
        metrics = self.repository.find_by_criteria(
            metrica=metrica,
            entidad=entidad,
            fecha_inicio=fecha_inicio,
            fecha_fin=fecha_fin or fecha_inicio,
            recurso=recurso
        )
        
        logger.info(f"‚úÖ {len(metrics)} registros encontrados")
        return metrics
    
    def get_latest_data_date(self, metrica: str) -> Optional[date]:
        """Obtener fecha m√°s reciente de datos para una m√©trica"""
        return self.repository.get_latest_date(metrica)
    
    def calculate_totals_by_resource(
        self,
        metrica: str,
        fecha_inicio: date,
        fecha_fin: date
    ) -> pd.DataFrame:
        """
        Calcular totales agrupados por recurso
        
        Returns:
            DataFrame con columnas: recurso, total_gwh
        """
        df = self.get_metrics(
            metrica=metrica,
            entidad='Recurso',
            fecha_inicio=fecha_inicio,
            fecha_fin=fecha_fin
        )
        
        if df.empty:
            return pd.DataFrame(columns=['recurso', 'total_gwh'])
        
        totals = df.groupby('recurso')['valor_gwh'].sum().reset_index()
        totals.columns = ['recurso', 'total_gwh']
        
        return totals.sort_values('total_gwh', ascending=False)
```

#### 5.3 Infrastructure - Repositorios (2 horas)

**Crear `infrastructure/database/connection.py`:**
```python
"""Gesti√≥n de conexiones a base de datos"""
import sqlite3
from contextlib import contextmanager
from typing import Generator
from pathlib import Path

from core.config import get_settings
from shared.logging import get_logger

settings = get_settings()
logger = get_logger(__name__)

DB_PATH = Path(settings.DATABASE_PATH)

@contextmanager
def get_connection() -> Generator[sqlite3.Connection, None, None]:
    """
    Context manager para conexi√≥n SQLite
    
    Uso:
        with get_connection() as conn:
            cursor = conn.cursor()
            cursor.execute("SELECT * FROM metrics")
    
    Yields:
        Conexi√≥n SQLite
    """
    conn = None
    try:
        conn = sqlite3.connect(
            str(DB_PATH),
            timeout=settings.DATABASE_TIMEOUT,
            check_same_thread=False
        )
        conn.row_factory = sqlite3.Row
        yield conn
    except sqlite3.Error as e:
        logger.error(f"Error de conexi√≥n SQLite: {e}")
        raise
    finally:
        if conn:
            conn.close()

class ConnectionPool:
    """Pool de conexiones SQLite (singleton)"""
    _instance = None
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance
    
    @contextmanager
    def get_connection(self) -> Generator[sqlite3.Connection, None, None]:
        """Obtener conexi√≥n del pool"""
        with get_connection() as conn:
            yield conn
```

**Crear `infrastructure/database/repositories/base_repository.py`:**
```python
"""Repositorio base con operaciones comunes"""
from abc import ABC, abstractmethod
from typing import Generic, TypeVar, List, Optional
import pandas as pd

from infrastructure.database.connection import get_connection
from shared.logging import get_logger

T = TypeVar('T')
logger = get_logger(__name__)

class BaseRepository(ABC, Generic[T]):
    """Repositorio base con patr√≥n Repository"""
    
    def __init__(self, table_name: str):
        self.table_name = table_name
    
    def find_all(self) -> pd.DataFrame:
        """Obtener todos los registros"""
        query = f"SELECT * FROM {self.table_name}"
        return self._execute_query(query)
    
    def find_by_id(self, id_value: int) -> Optional[T]:
        """Buscar por ID"""
        query = f"SELECT * FROM {self.table_name} WHERE id = ?"
        df = self._execute_query(query, (id_value,))
        return df.iloc[0].to_dict() if not df.empty else None
    
    def count(self) -> int:
        """Contar registros"""
        query = f"SELECT COUNT(*) as count FROM {self.table_name}"
        with get_connection() as conn:
            cursor = conn.cursor()
            result = cursor.execute(query).fetchone()
            return result['count']
    
    def _execute_query(self, query: str, params: tuple = ()) -> pd.DataFrame:
        """Ejecutar query y retornar DataFrame"""
        try:
            with get_connection() as conn:
                df = pd.read_sql_query(query, conn, params=params)
                return df
        except Exception as e:
            logger.error(f"Error ejecutando query: {e}")
            logger.debug(f"Query: {query}, Params: {params}")
            raise
    
    @abstractmethod
    def create(self, entity: T) -> int:
        """Crear nuevo registro"""
        pass
    
    @abstractmethod
    def update(self, entity: T) -> bool:
        """Actualizar registro"""
        pass
    
    @abstractmethod
    def delete(self, id_value: int) -> bool:
        """Eliminar registro"""
        pass
```

**Crear `infrastructure/database/repositories/metrics_repository.py`:**
```python
"""Repositorio de m√©tricas energ√©ticas"""
from datetime import date
from typing import Optional, List
import pandas as pd

from infrastructure.database.repositories.base_repository import BaseRepository
from domain.models.metric import Metric
from shared.logging import get_logger

logger = get_logger(__name__)

class MetricsRepository(BaseRepository[Metric]):
    """Repositorio para tabla metrics"""
    
    def __init__(self):
        super().__init__('metrics')
    
    def find_by_criteria(
        self,
        metrica: str,
        entidad: str,
        fecha_inicio: date,
        fecha_fin: date,
        recurso: Optional[str] = None,
        recurso_filter: Optional[List[str]] = None
    ) -> pd.DataFrame:
        """
        Buscar m√©tricas por criterios
        
        Args:
            metrica: C√≥digo m√©trica
            entidad: Entidad
            fecha_inicio: Fecha inicio
            fecha_fin: Fecha fin
            recurso: Filtro recurso √∫nico
            recurso_filter: Lista de recursos
            
        Returns:
            DataFrame con m√©tricas
        """
        query = """
            SELECT fecha, metrica, entidad, recurso, valor_gwh, unidad, fecha_actualizacion
            FROM metrics
            WHERE metrica = ? AND entidad = ? AND fecha BETWEEN ? AND ?
        """
        params = [metrica, entidad, fecha_inicio.isoformat(), fecha_fin.isoformat()]
        
        # Filtro por recurso √∫nico
        if recurso:
            query += " AND recurso = ?"
            params.append(recurso)
        
        # Filtro por lista de recursos
        if recurso_filter:
            placeholders = ','.join('?' * len(recurso_filter))
            query += f" AND recurso IN ({placeholders})"
            params.extend(recurso_filter)
        
        query += " ORDER BY fecha, recurso"
        
        return self._execute_query(query, tuple(params))
    
    def get_latest_date(self, metrica: str) -> Optional[date]:
        """Obtener fecha m√°s reciente para una m√©trica"""
        query = "SELECT MAX(fecha) as max_fecha FROM metrics WHERE metrica = ?"
        df = self._execute_query(query, (metrica,))
        
        if not df.empty and df['max_fecha'].iloc[0]:
            return pd.to_datetime(df['max_fecha'].iloc[0]).date()
        return None
    
    def get_unique_resources(self, metrica: str) -> List[str]:
        """Obtener lista de recursos √∫nicos para una m√©trica"""
        query = """
            SELECT DISTINCT recurso 
            FROM metrics 
            WHERE metrica = ? AND recurso IS NOT NULL
            ORDER BY recurso
        """
        df = self._execute_query(query, (metrica,))
        return df['recurso'].tolist()
    
    def create(self, entity: Metric) -> int:
        """Insertar nueva m√©trica"""
        # Implementar si es necesario
        raise NotImplementedError()
    
    def update(self, entity: Metric) -> bool:
        """Actualizar m√©trica"""
        # Implementar si es necesario
        raise NotImplementedError()
    
    def delete(self, id_value: int) -> bool:
        """Eliminar m√©trica"""
        # Implementar si es necesario
        raise NotImplementedError()
```

#### 5.4 Presentation - P√°ginas y Componentes (2 horas)

**Refactorizar p√°ginas** (ejemplo: `presentation/pages/generacion/general.py`):

```python
"""
P√°gina: Generaci√≥n - Vista General
Muestra m√©tricas generales de generaci√≥n energ√©tica
"""
import dash
from dash import html, dcc, callback, Input, Output
import dash_bootstrap_components as dbc
from datetime import date, timedelta

from presentation.components.filters import create_date_filter
from presentation.components.charts import create_line_chart, create_bar_chart
from presentation.components.cards import create_kpi_card
from domain.services.metrics_service import MetricsService
from infrastructure.database.repositories.metrics_repository import MetricsRepository
from shared.logging import get_logger

dash.register_page(__name__, path='/generacion/general', name='Generaci√≥n General')

logger = get_logger(__name__)

# Inyecci√≥n de dependencias
metrics_repo = MetricsRepository()
metrics_service = MetricsService(metrics_repo)

def layout():
    """Layout de la p√°gina"""
    return dbc.Container([
        dbc.Row([
            dbc.Col([
                html.H1("üìä Generaci√≥n Energ√©tica - Vista General"),
                html.P("An√°lisis de generaci√≥n total del sistema el√©ctrico colombiano")
            ])
        ], className="mb-4"),
        
        # Filtros
        dbc.Row([
            dbc.Col([
                create_date_filter(
                    id_prefix='gen-general',
                    default_days=30
                )
            ])
        ], className="mb-4"),
        
        # KPIs
        dbc.Row([
            dbc.Col(html.Div(id='gen-general-kpis'), md=12)
        ], className="mb-4"),
        
        # Gr√°ficos
        dbc.Row([
            dbc.Col([
                dcc.Graph(id='gen-general-chart-time')
            ], md=12)
        ], className="mb-4"),
        
        dbc.Row([
            dbc.Col([
                dcc.Graph(id='gen-general-chart-resources')
            ], md=6),
            dbc.Col([
                dcc.Graph(id='gen-general-chart-pie')
            ], md=6)
        ])
    ], fluid=True)

@callback(
    [Output('gen-general-kpis', 'children'),
     Output('gen-general-chart-time', 'figure'),
     Output('gen-general-chart-resources', 'figure'),
     Output('gen-general-chart-pie', 'figure')],
    [Input('gen-general-date-start', 'date'),
     Input('gen-general-date-end', 'date')]
)
def update_content(fecha_inicio_str: str, fecha_fin_str: str):
    """
    Actualizar contenido de la p√°gina
    
    Args:
        fecha_inicio_str: Fecha inicio (ISO format)
        fecha_fin_str: Fecha fin (ISO format)
        
    Returns:
        Tuple con (kpis, chart_time, chart_resources, chart_pie)
    """
    try:
        # Parsear fechas
        fecha_inicio = date.fromisoformat(fecha_inicio_str)
        fecha_fin = date.fromisoformat(fecha_fin_str)
        
        logger.info(f"Actualizando generaci√≥n general: {fecha_inicio} - {fecha_fin}")
        
        # Obtener datos
        df_sistema = metrics_service.get_metrics(
            metrica='Gene',
            entidad='Sistema',
            fecha_inicio=fecha_inicio,
            fecha_fin=fecha_fin
        )
        
        df_recursos = metrics_service.get_metrics(
            metrica='Gene',
            entidad='Recurso',
            fecha_inicio=fecha_inicio,
            fecha_fin=fecha_fin
        )
        
        # Calcular KPIs
        total_gwh = df_sistema['valor_gwh'].sum()
        promedio_diario = df_sistema['valor_gwh'].mean()
        dias = (fecha_fin - fecha_inicio).days + 1
        
        kpis = dbc.Row([
            dbc.Col(create_kpi_card("Total Generado", f"{total_gwh:,.0f} GWh", "‚ö°"), md=4),
            dbc.Col(create_kpi_card("Promedio Diario", f"{promedio_diario:,.0f} GWh", "üìä"), md=4),
            dbc.Col(create_kpi_card("Per√≠odo", f"{dias} d√≠as", "üìÖ"), md=4)
        ])
        
        # Gr√°fico temporal
        chart_time = create_line_chart(
            df_sistema,
            x='fecha',
            y='valor_gwh',
            title='Generaci√≥n Total del Sistema',
            xlabel='Fecha',
            ylabel='Generaci√≥n (GWh)'
        )
        
        # Gr√°fico por recursos
        df_totales = metrics_service.calculate_totals_by_resource(
            metrica='Gene',
            fecha_inicio=fecha_inicio,
            fecha_fin=fecha_fin
        )
        
        chart_resources = create_bar_chart(
            df_totales.head(10),
            x='recurso',
            y='total_gwh',
            title='Top 10 Recursos por Generaci√≥n',
            xlabel='Recurso',
            ylabel='Generaci√≥n Total (GWh)'
        )
        
        # Gr√°fico pie
        chart_pie = create_pie_chart(
            df_totales.head(5),
            values='total_gwh',
            names='recurso',
            title='Distribuci√≥n Top 5 Recursos'
        )
        
        return kpis, chart_time, chart_resources, chart_pie
        
    except Exception as e:
        logger.error(f"Error actualizando p√°gina: {e}", exc_info=True)
        # Retornar componentes vac√≠os con mensaje de error
        error_msg = html.Div("‚ö†Ô∏è Error cargando datos", className="alert alert-danger")
        return error_msg, {}, {}, {}
```

**Componentes reutilizables** (`presentation/components/charts.py`):

```python
"""Componentes de gr√°ficos reutilizables"""
import plotly.graph_objects as go
import plotly.express as px
import pandas as pd
from typing import Optional

def create_line_chart(
    df: pd.DataFrame,
    x: str,
    y: str,
    title: str,
    xlabel: str = "",
    ylabel: str = "",
    color: Optional[str] = None
) -> go.Figure:
    """
    Crear gr√°fico de l√≠neas
    
    Args:
        df: DataFrame con datos
        x: Columna para eje X
        y: Columna para eje Y
        title: T√≠tulo del gr√°fico
        xlabel: Etiqueta eje X
        ylabel: Etiqueta eje Y
        color: Columna para agrupar por color (opcional)
        
    Returns:
        Figura Plotly
    """
    fig = px.line(
        df,
        x=x,
        y=y,
        color=color,
        title=title,
        labels={x: xlabel, y: ylabel}
    )
    
    fig.update_layout(
        hovermode='x unified',
        template='plotly_white',
        title_font_size=18,
        title_font_color='#003366'
    )
    
    return fig

def create_bar_chart(
    df: pd.DataFrame,
    x: str,
    y: str,
    title: str,
    xlabel: str = "",
    ylabel: str = "",
    color: Optional[str] = None
) -> go.Figure:
    """Crear gr√°fico de barras"""
    fig = px.bar(
        df,
        x=x,
        y=y,
        color=color,
        title=title,
        labels={x: xlabel, y: ylabel}
    )
    
    fig.update_layout(
        template='plotly_white',
        title_font_size=18,
        title_font_color='#003366'
    )
    
    return fig

def create_pie_chart(
    df: pd.DataFrame,
    values: str,
    names: str,
    title: str
) -> go.Figure:
    """Crear gr√°fico pie"""
    fig = px.pie(
        df,
        values=values,
        names=names,
        title=title
    )
    
    fig.update_traces(textposition='inside', textinfo='percent+label')
    fig.update_layout(
        template='plotly_white',
        title_font_size=18,
        title_font_color='#003366'
    )
    
    return fig
```

#### 5.5 Infrastructure/ETL - Refactorizar Pipeline (1 hora)

**Crear `infrastructure/etl/pipeline.py`:**

```python
"""
Pipeline ETL principal
Orquesta extracci√≥n, transformaci√≥n y carga de datos desde API XM
"""
from datetime import date, timedelta
from typing import List

from infrastructure.etl.extractors.xm_extractor import XMExtractor
from infrastructure.etl.transformers.unit_converter import UnitConverter
from infrastructure.etl.loaders.db_loader import DBLoader
from infrastructure.etl.validators.data_validator import DataValidator
from infrastructure.etl.config.metrics_config import METRICAS_CONFIG
from shared.logging import get_logger

logger = get_logger(__name__)

class ETLPipeline:
    """Pipeline ETL para m√©tricas energ√©ticas"""
    
    def __init__(self):
        self.extractor = XMExtractor()
        self.converter = UnitConverter()
        self.loader = DBLoader()
        self.validator = DataValidator()
    
    def run(
        self,
        fecha_inicio: date,
        fecha_fin: date,
        metricas: List[str] = None
    ) -> dict:
        """
        Ejecutar pipeline ETL completo
        
        Args:
            fecha_inicio: Fecha inicio
            fecha_fin: Fecha fin
            metricas: Lista de m√©tricas (None = todas)
            
        Returns:
            Diccionario con resultados: {
                'success': bool,
                'metrics_processed': int,
                'records_inserted': int,
                'errors': list
            }
        """
        logger.info("="*70)
        logger.info("INICIANDO PIPELINE ETL")
        logger.info(f"Per√≠odo: {fecha_inicio} - {fecha_fin}")
        logger.info("="*70)
        
        # Seleccionar m√©tricas a procesar
        if metricas is None:
            metricas_to_process = METRICAS_CONFIG.keys()
        else:
            metricas_to_process = metricas
        
        results = {
            'success': True,
            'metrics_processed': 0,
            'records_inserted': 0,
            'errors': []
        }
        
        for metrica in metricas_to_process:
            try:
                logger.info(f"\nüìä Procesando: {metrica}")
                
                # 1. EXTRACT
                df_raw = self.extractor.extract(metrica, fecha_inicio, fecha_fin)
                
                if df_raw.empty:
                    logger.warning(f"  ‚ö†Ô∏è Sin datos para {metrica}")
                    continue
                
                # 2. TRANSFORM
                df_transformed = self.converter.convert(df_raw, metrica)
                
                # 3. VALIDATE
                is_valid, validation_errors = self.validator.validate(df_transformed, metrica)
                
                if not is_valid:
                    logger.error(f"  ‚ùå Validaci√≥n fall√≥: {validation_errors}")
                    results['errors'].append({
                        'metrica': metrica,
                        'errors': validation_errors
                    })
                    results['success'] = False
                    continue
                
                # 4. LOAD
                records_inserted = self.loader.load(df_transformed, metrica)
                
                results['metrics_processed'] += 1
                results['records_inserted'] += records_inserted
                
                logger.info(f"  ‚úÖ {metrica}: {records_inserted} registros insertados")
                
            except Exception as e:
                logger.error(f"  ‚ùå Error procesando {metrica}: {e}", exc_info=True)
                results['errors'].append({
                    'metrica': metrica,
                    'error': str(e)
                })
                results['success'] = False
        
        logger.info("="*70)
        logger.info(f"ETL COMPLETADO - M√©tricas: {results['metrics_processed']}, Registros: {results['records_inserted']}")
        logger.info("="*70)
        
        return results
    
    def run_incremental(self, days_back: int = 7) -> dict:
        """
        Ejecutar ETL incremental (√∫ltimos N d√≠as)
        
        Args:
            days_back: D√≠as hacia atr√°s desde hoy
            
        Returns:
            Resultados del pipeline
        """
        fecha_fin = date.today()
        fecha_inicio = fecha_fin - timedelta(days=days_back)
        
        return self.run(fecha_inicio, fecha_fin)
```

---

### FASE 6: Tests y Calidad (2 horas)

**Crear estructura de tests:**

```python
# tests/conftest.py
"""Fixtures de pytest"""
import pytest
from pathlib import Path
import sqlite3

@pytest.fixture
def test_db_path(tmp_path):
    """Crear BD de prueba temporal"""
    db_path = tmp_path / "test_portal.db"
    # Crear esquema
    conn = sqlite3.connect(str(db_path))
    conn.executescript("""
        CREATE TABLE IF NOT EXISTS metrics (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            fecha DATE NOT NULL,
            metrica TEXT NOT NULL,
            entidad TEXT NOT NULL,
            recurso TEXT,
            valor_gwh REAL NOT NULL,
            unidad TEXT,
            fecha_actualizacion DATE DEFAULT CURRENT_DATE
        );
    """)
    conn.close()
    return db_path

@pytest.fixture
def metrics_repository(test_db_path, monkeypatch):
    """Repository con BD de prueba"""
    from infrastructure.database.repositories.metrics_repository import MetricsRepository
    monkeypatch.setattr('infrastructure.database.connection.DB_PATH', test_db_path)
    return MetricsRepository()
```

```python
# tests/unit/test_services/test_metrics_service.py
"""Tests unitarios para MetricsService"""
import pytest
from datetime import date
from domain.services.metrics_service import MetricsService

def test_get_metrics_success(metrics_repository):
    """Test: obtener m√©tricas exitosamente"""
    service = MetricsService(metrics_repository)
    
    fecha = date(2026, 1, 1)
    df = service.get_metrics(
        metrica='Gene',
        entidad='Sistema',
        fecha_inicio=fecha,
        fecha_fin=fecha
    )
    
    assert not df.empty  # Deber√≠a tener datos de fixture
    assert 'valor_gwh' in df.columns

def test_calculate_totals_by_resource(metrics_repository):
    """Test: calcular totales por recurso"""
    service = MetricsService(metrics_repository)
    
    df = service.calculate_totals_by_resource(
        metrica='Gene',
        fecha_inicio=date(2026, 1, 1),
        fecha_fin=date(2026, 1, 31)
    )
    
    assert not df.empty
    assert list(df.columns) == ['recurso', 'total_gwh']
    assert df['total_gwh'].sum() > 0
```

---

### FASE 7: Deployment y Documentaci√≥n (1 hora)

**Actualizar deployment configs:**

```yaml
# deployment/docker/docker-compose.yml
version: '3.8'

services:
  dashboard:
    build:
      context: ../..
      dockerfile: deployment/docker/Dockerfile
    ports:
      - "8050:8050"
    environment:
      - DATABASE_PATH=/app/data/portal_energetico.db
      - GROQ_API_KEY=${GROQ_API_KEY}
      - OPENROUTER_API_KEY=${OPENROUTER_API_KEY}
    volumes:
      - ../../portal_energetico.db:/app/data/portal_energetico.db
      - ../../logs:/app/logs
    restart: unless-stopped
    command: gunicorn wsgi:application -c deployment/gunicorn_config.py
```

**Documentar arquitectura:**

```markdown
# docs/architecture/README.md

# Arquitectura del Sistema

## Principios de Dise√±o

1. **Separaci√≥n de Concerns (SoC)**
   - Presentation: UI y callbacks Dash
   - Domain: L√≥gica de negocio
   - Infrastructure: Adaptadores (DB, APIs externas, ML)

2. **Dependency Inversion**
   - Domain no depende de Infrastructure
   - Infrastructure implementa interfaces de Domain
   - Inyecci√≥n de dependencias

3. **Single Responsibility**
   - Cada m√≥dulo/clase tiene una responsabilidad clara
   - Services para l√≥gica de negocio
   - Repositories para acceso a datos
   - Components para UI reutilizable

## Flujo de Datos

```
External APIs ‚Üí Infrastructure/ETL ‚Üí Infrastructure/Database
                                              ‚Üì
UI (Dash) ‚Üê Presentation/Pages ‚Üê Domain/Services ‚Üê Infrastructure/Repositories
```

## Capas

### Core
Configuraci√≥n y factory de aplicaci√≥n. Sin l√≥gica de negocio.

### Presentation
UI y callbacks Dash. Solo maneja interacci√≥n con usuario.
Llama a Services para obtener datos.

### Domain
L√≥gica de negocio pura. Independiente de frameworks.
Models (dataclasses) y Services (operaciones de negocio).

### Infrastructure
Adaptadores a tecnolog√≠as externas:
- Database: SQLite con patr√≥n Repository
- External: APIs (XM, GROQ, OpenRouter)
- ML: Modelos Prophet/SARIMA
- ETL: Pipeline de datos

### Shared
C√≥digo compartido entre capas: logging, utils, decorators.

## Patrones Utilizados

- **Repository Pattern**: Abstracci√≥n de acceso a datos
- **Factory Pattern**: Creaci√≥n de app Dash
- **Service Pattern**: L√≥gica de negocio encapsulada
- **Dependency Injection**: Inyecci√≥n manual en callbacks
```

---

## üóëÔ∏è LIMPIEZA DE ARCHIVOS

### Archivos a Archivar

**Mover a `legacy/`:**

```bash
# Archivos legacy comprobados
mv backup_originales/ legacy/
mv notebooks/ legacy/  # Despu√©s de revisar
mv siea/ legacy/  # Si no se usa

# Crear README en legacy
cat > legacy/README.md << 'EOF'
# Archivos Legacy

Este directorio contiene c√≥digo antiguo que ya no se usa en producci√≥n.

## Contenido

- `backup_originales/`: Generadores antiguos (pre-refactorizaci√≥n)
- `notebooks/`: Notebooks Jupyter de exploraci√≥n
- `siea/`: Sistema SIEA (sin uso confirmado)

‚ö†Ô∏è **NO USAR ESTOS ARCHIVOS EN PRODUCCI√ìN**
EOF
```

### Archivos a Eliminar

```bash
# Cache Python residual
find . -type d -name "__pycache__" -exec rm -rf {} + 2>/dev/null
find . -type f -name "*.pyc" -delete
find . -type f -name "*.pyo" -delete

# Duplicados confirmados
rm -f pages/utils_xm.py  # Duplicado de utils/_xm.py
```

### Assets a Consolidar

```bash
# Consolidar CSS
cat assets/*.css > assets/css/main.css
# Revisar y eliminar CSS individuales si no se usan

# Consolidar JS
cat assets/*.js > assets/js/main.js
# Revisar y eliminar JS individuales
```

---

## ‚öôÔ∏è MEJORAS DE INFRAESTRUCTURA

### Preparaci√≥n para PostgreSQL

**Crear abstracci√≥n con SQLAlchemy:**

```python
# infrastructure/database/models.py
"""Modelos SQLAlchemy (preparaci√≥n PostgreSQL)"""
from sqlalchemy import Column, Integer, String, Float, Date, Index
from sqlalchemy.ext.declarative import declarative_base

Base = declarative_base()

class MetricModel(Base):
    """Modelo ORM para m√©tricas"""
    __tablename__ = 'metrics'
    
    id = Column(Integer, primary_key=True, autoincrement=True)
    fecha = Column(Date, nullable=False, index=True)
    metrica = Column(String, nullable=False, index=True)
    entidad = Column(String, nullable=False)
    recurso = Column(String, nullable=True)
    valor_gwh = Column(Float, nullable=False)
    unidad = Column(String)
    fecha_actualizacion = Column(Date)
    
    __table_args__ = (
        Index('idx_metrica_fecha', 'metrica', 'fecha'),
        Index('idx_metrica_entidad_recurso', 'metrica', 'entidad', 'recurso'),
    )
```

### Systemd Service Mejorado

```ini
# deployment/systemd/dashboard-mme.service
[Unit]
Description=Dashboard Portal Energ√©tico MME
After=network.target postgresql.service
Wants=postgresql.service

[Service]
Type=notify
User=admonctrlxm
Group=admonctrlxm
WorkingDirectory=/home/admonctrlxm/server
Environment="PATH=/home/admonctrlxm/server/venv/bin:/usr/bin"
Environment="PYTHONPATH=/home/admonctrlxm/server"
EnvironmentFile=/home/admonctrlxm/server/.env
ExecStart=/home/admonctrlxm/server/venv/bin/gunicorn wsgi:application -c deployment/gunicorn_config.py
ExecReload=/bin/kill -s HUP $MAINPID
ExecStop=/bin/kill -s TERM $MAINPID
KillMode=mixed
TimeoutStopSec=5
PrivateTmp=true
Restart=always
RestartSec=10

# Recursos
LimitNOFILE=65536
LimitNPROC=4096

# Security (sin cambios)
NoNewPrivileges=true
ProtectSystem=strict
ProtectHome=read-only
ReadWritePaths=/home/admonctrlxm/server/logs
ReadWritePaths=/home/admonctrlxm/server/portal_energetico.db
ReadWritePaths=/home/admonctrlxm/server/portal_energetico.db-shm
ReadWritePaths=/home/admonctrlxm/server/portal_energetico.db-wal
ReadWritePaths=/tmp

[Install]
WantedBy=multi-user.target
```

---

## üìè CRITERIOS DE CALIDAD

### Code Style

```python
# .flake8
[flake8]
max-line-length = 100
exclude = .git,__pycache__,legacy,venv
ignore = E203,W503

# .pylintrc
[MASTER]
ignore=legacy,venv
max-line-length=100

[MESSAGES CONTROL]
disable=missing-docstring,too-few-public-methods
```

### Type Checking

```ini
# mypy.ini
[mypy]
python_version = 3.10
warn_return_any = True
warn_unused_configs = True
disallow_untyped_defs = True
ignore_missing_imports = True

[mypy-legacy.*]
ignore_errors = True
```

### Pre-commit Hooks

```yaml
# .pre-commit-config.yaml
repos:
  - repo: https://github.com/psf/black
    rev: 23.1.0
    hooks:
      - id: black
        language_version: python3.10
  
  - repo: https://github.com/PyCQA/flake8
    rev: 6.0.0
    hooks:
      - id: flake8
  
  - repo: https://github.com/pre-commit/mirrors-mypy
    rev: v1.0.1
    hooks:
      - id: mypy
        additional_dependencies: [types-all]
```

---

## ‚úÖ CHECKLIST DE MIGRACI√ìN

### Fase 4: Estructura
- [ ] Crear directorios nuevos (core, presentation, domain, infrastructure, shared, api)
- [ ] Mover archivos deployment a deployment/
- [ ] Mover assets y consolidar CSS/JS
- [ ] Archivar legacy (backup_originales/, notebooks/, siea/)
- [ ] Eliminar duplicados (pages/utils_xm.py, cache residual)

### Fase 5: Refactorizaci√≥n
- [ ] Crear core/config.py y core/app_factory.py
- [ ] Refactorizar app.py (206 ‚Üí 30 l√≠neas)
- [ ] Crear domain/models/ (Metric, Prediction, Health)
- [ ] Crear domain/services/ (MetricsService, PredictionsService, AIService, HealthService)
- [ ] Crear infrastructure/database/repositories/ (BaseRepository, MetricsRepository)
- [ ] Refactorizar infrastructure/etl/ (pipeline, extractors, transformers, loaders)
- [ ] Refactorizar presentation/pages/ (separar UI de l√≥gica)
- [ ] Crear presentation/components/ (charts, tables, cards, filters)
- [ ] Crear shared/logging/ y shared/utils/

### Fase 6: Tests
- [ ] Crear tests/conftest.py con fixtures
- [ ] Tests unitarios de services
- [ ] Tests unitarios de repositories
- [ ] Tests de integraci√≥n ETL
- [ ] Configurar pytest.ini

### Fase 7: Deployment
- [ ] Actualizar deployment/gunicorn_config.py
- [ ] Actualizar deployment/systemd/dashboard-mme.service
- [ ] Crear deployment/docker/Dockerfile
- [ ] Crear deployment/docker/docker-compose.yml
- [ ] Documentar arquitectura en docs/architecture/

### Calidad
- [ ] Configurar .flake8, .pylintrc, mypy.ini
- [ ] Configurar .pre-commit-config.yaml
- [ ] A√±adir type hints en funciones cr√≠ticas
- [ ] Actualizar docstrings
- [ ] Verificar logging consistente

---

## üìä M√âTRICAS DE √âXITO

### Antes de Refactorizaci√≥n
- app.py: 206 l√≠neas (monolito)
- Estructura: 8 carpetas ra√≠z
- Duplicaci√≥n: 2 archivos (_xm.py)
- Tests: 0 tests automatizados
- Type hints: <10% funciones
- Acoplamiento: Alto (p√°ginas ‚Üí DB directo)
- Reutilizaci√≥n: Baja (l√≥gica en callbacks)

### Despu√©s de Refactorizaci√≥n (Target)
- app.py: 30 l√≠neas (factory pattern)
- Estructura: 15 carpetas organizadas por capa
- Duplicaci√≥n: 0 (eliminada)
- Tests: >50 tests automatizados
- Type hints: >80% funciones p√∫blicas
- Acoplamiento: Bajo (capas desacopladas)
- Reutilizaci√≥n: Alta (services, components)
- Preparaci√≥n API: Lista (services reutilizables)

---

## üîÑ ESTRATEGIA DE MIGRACI√ìN GRADUAL

### Enfoque Estrangulation Pattern

1. **Crear nueva estructura en paralelo** (no romper existente)
2. **Migrar m√≥dulo por m√≥dulo** (empezar con menos cr√≠ticos)
3. **Mantener compatibilidad** (imports antiguos siguen funcionando)
4. **Tests de regresi√≥n** (verificar funcionalidad intacta)
5. **Eliminar c√≥digo antiguo** (cuando nueva versi√≥n est√© estable)

### Orden de Migraci√≥n Sugerido

1. ‚úÖ **shared/** (logging, utils) - Sin dependencias
2. ‚úÖ **core/** (config, app_factory) - Dependencias m√≠nimas
3. ‚úÖ **infrastructure/database/** (connection, repositories) - Base para todo
4. ‚úÖ **domain/models/** - Solo dataclasses
5. ‚úÖ **domain/services/** - L√≥gica de negocio
6. ‚úÖ **infrastructure/etl/** - Pipeline independiente
7. ‚úÖ **presentation/components/** - UI reutilizable
8. ‚úÖ **presentation/pages/** - √öltima capa (depende de todo)

---

## üìû SOPORTE Y PR√ìXIMOS PASOS

### Despu√©s de Refactorizaci√≥n

1. **Monitoreo post-migraci√≥n**
   - Verificar performance (tiempos de respuesta)
   - Revisar logs de errores
   - Validar funcionalidad cr√≠tica

2. **Documentaci√≥n adicional**
   - ADRs (Architecture Decision Records)
   - Diagramas UML
   - API documentation (cuando se cree)

3. **Mejoras futuras**
   - Migraci√≥n a PostgreSQL
   - API REST con FastAPI
   - Autenticaci√≥n/Autorizaci√≥n
   - Cache distribuido (Redis)
   - Monitoreo con Grafana/Prometheus

---

**Generado:** 28 de enero de 2026  
**Versi√≥n:** 1.0  
**Estado:** Plan aprobado, listo para ejecuci√≥n
